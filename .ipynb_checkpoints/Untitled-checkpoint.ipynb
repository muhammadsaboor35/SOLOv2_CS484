{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5f8ba6-8330-43c1-944e-233028b0aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"trashcan_instance_train\", {}, \"/home/outletters/trashcan/Augmented/train_annotation.json\", \"/home/outletters/trashcan/Augmented/train_output\")\n",
    "register_coco_instances(\"trashcan_instance_val\", {}, \"/home/outletters/trashcan/Augmented/val_annotation.json\", \"/home/outletters/trashcan/Augmented/val_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0889f518-296f-4652-a6fc-de02f45c7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "\n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):\n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        # self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        # return losses\n",
    "        return mean_loss\n",
    "\n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop\n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "\n",
    "    def after_step(self):\n",
    "        next_iter = int(self.trainer.iter) + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            mean_loss = self._do_loss_eval()\n",
    "            self.trainer.storage.put_scalars(validation_loss=mean_loss)\n",
    "            print(\"validation do loss eval\", mean_loss)\n",
    "        else:\n",
    "            pass\n",
    "            # self.trainer.storage.put_scalars(timetest=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227eac38-d09c-4e11-8cd5-b6ca62bede3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "\"\"\"\n",
    "Detection Training Script.\n",
    "\n",
    "This scripts reads a given config file and runs the training or evaluation.\n",
    "It is an entry point that is made to train standard models in detectron2.\n",
    "\n",
    "In order to let one script support training of many models,\n",
    "this script contains logic that are specific to these built-in models and therefore\n",
    "may not be suitable for your own project.\n",
    "For example, your research project perhaps only needs a single \"evaluator\".\n",
    "\n",
    "Therefore, we recommend you to use detectron2 as an library and take\n",
    "this file as an example of how to use the library.\n",
    "You may want to write your own script with your datasets and other customizations.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import argparse\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.data import MetadataCatalog, build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, hooks, launch\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.evaluation import (\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    verify_results,\n",
    ")\n",
    "from detectron2.modeling import GeneralizedRCNNWithTTA\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "from adet.data.dataset_mapper import DatasetMapperWithBasis\n",
    "from adet.config import get_cfg\n",
    "from adet.checkpoint import AdetCheckpointer\n",
    "from adet.evaluation import TextEvaluator\n",
    "\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    This is the same Trainer except that we rewrite the\n",
    "    `build_train_loader`/`resume_or_load` method.\n",
    "    \"\"\"\n",
    "    def resume_or_load(self, resume=True):\n",
    "        if not isinstance(self.checkpointer, AdetCheckpointer):\n",
    "            # support loading a few other backbones\n",
    "            self.checkpointer = AdetCheckpointer(\n",
    "                self.model,\n",
    "                self.cfg.OUTPUT_DIR,\n",
    "                optimizer=self.optimizer,\n",
    "                scheduler=self.scheduler,\n",
    "            )\n",
    "        super().resume_or_load(resume=resume)\n",
    "\n",
    "    def train_loop(self, start_iter: int, max_iter: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            start_iter, max_iter (int): See docs above\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(\"adet.trainer\")\n",
    "        logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
    "\n",
    "        self.iter = self.start_iter = start_iter\n",
    "\n",
    "        with EventStorage(start_iter) as self.storage:\n",
    "            self.before_train()\n",
    "            for self.iter in range(self.start_iter, self.max_iter):\n",
    "                self.before_step()\n",
    "                self.run_step()\n",
    "                self.after_step()\n",
    "            self.after_train()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Run training.\n",
    "\n",
    "        Returns:\n",
    "            OrderedDict of results, if evaluation is enabled. Otherwise None.\n",
    "        \"\"\"\n",
    "        print(\"Max iter: \", self.max_iter, self.start_iter)\n",
    "        self.train_loop(0, self.max_iter)\n",
    "        if hasattr(self, \"_last_eval_results\") and comm.is_main_process():\n",
    "            verify_results(self.cfg, self._last_eval_results)\n",
    "            return self._last_eval_results\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            iterable\n",
    "\n",
    "        It calls :func:`detectron2.data.build_detection_train_loader` with a customized\n",
    "        DatasetMapper, which adds categorical labels as a semantic mask.\n",
    "        \"\"\"\n",
    "        mapper = DatasetMapperWithBasis(cfg, True)\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        \"\"\"\n",
    "        Create evaluator(s) for a given dataset.\n",
    "        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
    "        For your own dataset, you can simply create an evaluator manually in your\n",
    "        script and do not have to worry about the hacky if-else logic here.\n",
    "        \"\"\"\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        evaluator_list = []\n",
    "        evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
    "        if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n",
    "            evaluator_list.append(\n",
    "                SemSegEvaluator(\n",
    "                    dataset_name,\n",
    "                    distributed=True,\n",
    "                    num_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES,\n",
    "                    ignore_label=cfg.MODEL.SEM_SEG_HEAD.IGNORE_VALUE,\n",
    "                    output_dir=output_folder,\n",
    "                )\n",
    "            )\n",
    "        if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n",
    "            evaluator_list.append(COCOEvaluator(dataset_name, cfg, True, output_folder))\n",
    "        if evaluator_type == \"coco_panoptic_seg\":\n",
    "            evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n",
    "        if evaluator_type == \"pascal_voc\":\n",
    "            return PascalVOCDetectionEvaluator(dataset_name)\n",
    "        if evaluator_type == \"lvis\":\n",
    "            return LVISEvaluator(dataset_name, cfg, True, output_folder)\n",
    "        if evaluator_type == \"text\":\n",
    "            return TextEvaluator(dataset_name, cfg, True, output_folder)\n",
    "        if len(evaluator_list) == 0:\n",
    "            raise NotImplementedError(\n",
    "                \"no Evaluator for the dataset {} with the type {}\".format(\n",
    "                    dataset_name, evaluator_type\n",
    "                )\n",
    "            )\n",
    "        if len(evaluator_list) == 1:\n",
    "            return evaluator_list[0]\n",
    "        return DatasetEvaluators(evaluator_list)\n",
    "\n",
    "    @classmethod\n",
    "    def test_with_TTA(cls, cfg, model):\n",
    "        logger = logging.getLogger(\"adet.trainer\")\n",
    "        # In the end of training, run an evaluation with TTA\n",
    "        # Only support some R-CNN models.\n",
    "        logger.info(\"Running inference with test-time augmentation ...\")\n",
    "        model = GeneralizedRCNNWithTTA(cfg, model)\n",
    "        evaluators = [\n",
    "            cls.build_evaluator(\n",
    "                cfg, name, output_folder=os.path.join(cfg.OUTPUT_DIR, \"inference_TTA\")\n",
    "            )\n",
    "            for name in cfg.DATASETS.TEST\n",
    "        ]\n",
    "        res = cls.test(cfg, model, evaluators)\n",
    "        res = OrderedDict({k + \"_TTA\": v for k, v in res.items()})\n",
    "        return res\n",
    "    \n",
    "#     def build_hooks(self):\n",
    "#         hooks = super(Trainer, self).build_hooks()\n",
    "#         cfg = self.cfg\n",
    "#         if len(cfg.DATASETS.TEST) > 0:\n",
    "#             loss_eval_hook = LossEvalHook(\n",
    "#                 cfg.TEST.EVAL_PERIOD,\n",
    "#                 self.model,\n",
    "#                 Trainer.build_test_loader(cfg, cfg.DATASETS.TEST[0]),\n",
    "#             )\n",
    "#             hooks.insert(-1, loss_eval_hook)\n",
    "\n",
    "#         return hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e4daf0-61d6-4d43-b3a3-2c155c33d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo patchelf --set-rpath ./ /usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc.so\n",
    "!sudo patchelf --set-rpath ./ /usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc.so.11.0\n",
    "!sudo patchelf --set-rpath ./ /usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc.so.11.0.221\n",
    "!sudo patchelf --set-rpath ./ /usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc-builtins.so\n",
    "!sudo patchelf --set-rpath ./ /usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc-builtins.so.11.0\n",
    "!sudo patchelf --set-rpath ./ /usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc-builtins.so.11.0.221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824c71c6-9106-4211-87d1-bf9210c0d9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-10.0/targets/x86_64-linux/lib/libnvrtc.so\n",
      "/usr/local/cuda-10.0/targets/x86_64-linux/lib/libnvrtc.so.10.0\n",
      "/usr/local/cuda-10.0/targets/x86_64-linux/lib/libnvrtc.so.10.0.130\n",
      "/usr/local/cuda-10.0/targets/x86_64-linux/lib/stubs/libnvrtc.so\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc.so\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc.so.11.0\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/libnvrtc.so.11.0.221\n",
      "/usr/local/cuda-11.0/targets/x86_64-linux/lib/stubs/libnvrtc.so\n"
     ]
    }
   ],
   "source": [
    "!sudo updatedb; locate libnvrtc.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e07b2f9-19df-4a79-a32d-2eef52fbbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(args):\n",
    "    \"\"\"\n",
    "    Create configs and perform basic setups.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.MODEL.SOLOV2.NUM_CLASSES = 22\n",
    "    \n",
    "    cfg.freeze()\n",
    "    default_setup(cfg, args)\n",
    "\n",
    "    rank = comm.get_rank()\n",
    "    setup_logger(cfg.OUTPUT_DIR, distributed_rank=rank, name=\"adet\")\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    cfg = setup(args)\n",
    "\n",
    "    if args.eval_only:\n",
    "        model = Trainer.build_model(cfg)\n",
    "        AdetCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
    "            cfg.MODEL.WEIGHTS, resume=args.resume\n",
    "        )\n",
    "        res = Trainer.test(cfg, model) # d2 defaults.py\n",
    "        if comm.is_main_process():\n",
    "            verify_results(cfg, res)\n",
    "        if cfg.TEST.AUG.ENABLED:\n",
    "            res.update(Trainer.test_with_TTA(cfg, model))\n",
    "        return res\n",
    "\n",
    "    \"\"\"\n",
    "    If you'd like to do anything fancier than the standard training logic,\n",
    "    consider writing your own training loop or subclassing the trainer.\n",
    "    \"\"\"\n",
    "    trainer = Trainer(cfg)\n",
    "    trainer.resume_or_load(resume=args.resume)\n",
    "    if cfg.TEST.AUG.ENABLED:\n",
    "        trainer.register_hooks(\n",
    "            [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]\n",
    "        )\n",
    "    return trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32374fe6-f898-4c04-a21d-52b467708731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='trashcan_instance_train',\n",
       "          json_file='/home/outletters/trashcan/Augmented/train_annotation.json',\n",
       "          image_root='/home/outletters/trashcan/Augmented/train_output',\n",
       "          evaluator_type='coco')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.data import MetadataCatalog\n",
    "MetadataCatalog.get(\"trashcan_instance_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605c4aba-3438-4d6d-b5fe-7d2fef5cbc48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Args: Namespace(config_file='configs/SOLOv2/R50_1x.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x'], resume=True)\n",
      "\u001b[32m[05/18 01:07:23 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[05/18 01:07:29 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ----------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]\n",
      "numpy                   1.19.4\n",
      "detectron2              0.4 @/home/outletters/.local/lib/python3.6/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 11.0\n",
      "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.7.1+cu110 @/home/outletters/.local/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   NVIDIA Tesla K80 (arch=3.7)\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  8.2.0\n",
      "torchvision             0.8.2+cu110 @/home/outletters/.local/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0\n",
      "fvcore                  0.1.3.post20210317\n",
      "cv2                     4.5.1\n",
      "----------------------  ----------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "\u001b[32m[05/18 01:07:29 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/SOLOv2/R50_1x.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x'], resume=True)\n",
      "\u001b[32m[05/18 01:07:29 detectron2]: \u001b[0mContents of args.config_file=configs/SOLOv2/R50_1x.yaml:\n",
      "_BASE_: \"Base-SOLOv2.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (3000, 4000)\n",
      "  MAX_ITER: 4500\n",
      "\n",
      "\u001b[32m[05/18 01:07:29 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('trashcan_instance_val',)\n",
      "  TRAIN: ('trashcan_instance_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    CROP_INSTANCE: True\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  HFLIP_TRAIN: True\n",
      "  MASK_FORMAT: bitmask\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 64, 128, 256, 512]]\n",
      "  BACKBONE:\n",
      "    ANTI_ALIAS: False\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  BASIS_MODULE:\n",
      "    ANN_SET: coco\n",
      "    COMMON_STRIDE: 8\n",
      "    CONVS_DIM: 128\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5']\n",
      "    LOSS_ON: False\n",
      "    LOSS_WEIGHT: 0.3\n",
      "    NAME: ProtoNet\n",
      "    NORM: SyncBN\n",
      "    NUM_BASES: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 3\n",
      "  BATEXT:\n",
      "    CANONICAL_SIZE: 96\n",
      "    CONV_DIM: 256\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4']\n",
      "    NUM_CHARS: 25\n",
      "    NUM_CONV: 2\n",
      "    POOLER_RESOLUTION: (8, 32)\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625)\n",
      "    RECOGNITION_LOSS: ctc\n",
      "    RECOGNIZER: attn\n",
      "    SAMPLING_RATIO: 1\n",
      "    VOC_SIZE: 96\n",
      "  BLENDMASK:\n",
      "    ATTN_SIZE: 14\n",
      "    BOTTOM_RESOLUTION: 56\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "    POOLER_SAMPLING_RATIO: 1\n",
      "    POOLER_SCALES: (0.25,)\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    TOP_INTERP: bilinear\n",
      "    VISUALIZE: False\n",
      "  BOXINST:\n",
      "    BOTTOM_PIXELS_REMOVED: 10\n",
      "    ENABLED: False\n",
      "    PAIRWISE:\n",
      "      COLOR_THRESH: 0.3\n",
      "      DILATION: 2\n",
      "      SIZE: 3\n",
      "      WARMUP_ITERS: 10000\n",
      "  BiFPN:\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    NUM_REPEATS: 6\n",
      "    OUT_CHANNELS: 160\n",
      "  CONDINST:\n",
      "    BOTTOM_PIXELS_REMOVED: -1\n",
      "    MASK_BRANCH:\n",
      "      CHANNELS: 128\n",
      "      IN_FEATURES: ['p3', 'p4', 'p5']\n",
      "      NORM: BN\n",
      "      NUM_CONVS: 4\n",
      "      OUT_CHANNELS: 8\n",
      "      SEMANTIC_LOSS_ON: False\n",
      "    MASK_HEAD:\n",
      "      CHANNELS: 8\n",
      "      DISABLE_REL_COORDS: False\n",
      "      NUM_LAYERS: 3\n",
      "      USE_FP16: False\n",
      "    MASK_OUT_STRIDE: 4\n",
      "    MAX_PROPOSALS: -1\n",
      "    TOPK_PROPOSALS_PER_IM: -1\n",
      "  DEVICE: cuda\n",
      "  DLA:\n",
      "    CONV_BODY: DLA34\n",
      "    NORM: FrozenBN\n",
      "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
      "  FCOS:\n",
      "    BOX_QUALITY: ctrness\n",
      "    CENTER_SAMPLE: True\n",
      "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
      "    INFERENCE_TH_TEST: 0.05\n",
      "    INFERENCE_TH_TRAIN: 0.05\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    LOC_LOSS_TYPE: giou\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    LOSS_NORMALIZER_CLS: fg\n",
      "    LOSS_WEIGHT_CLS: 1.0\n",
      "    NMS_TH: 0.6\n",
      "    NORM: GN\n",
      "    NUM_BOX_CONVS: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CLS_CONVS: 4\n",
      "    NUM_SHARE_CONVS: 0\n",
      "    POST_NMS_TOPK_TEST: 100\n",
      "    POST_NMS_TOPK_TRAIN: 100\n",
      "    POS_RADIUS: 1.5\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
      "    THRESH_WITH_CTR: False\n",
      "    TOP_LEVELS: 2\n",
      "    USE_DEFORMABLE: False\n",
      "    USE_RELU: True\n",
      "    USE_SCALE: True\n",
      "    YIELD_PROPOSAL: False\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  MEInst:\n",
      "    AGNOSTIC: True\n",
      "    CENTER_SAMPLE: True\n",
      "    DIM_MASK: 60\n",
      "    FLAG_PARAMETERS: False\n",
      "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
      "    GCN_KERNEL_SIZE: 9\n",
      "    INFERENCE_TH_TEST: 0.05\n",
      "    INFERENCE_TH_TRAIN: 0.05\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    LAST_DEFORMABLE: False\n",
      "    LOC_LOSS_TYPE: giou\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    LOSS_ON_MASK: False\n",
      "    MASK_LOSS_TYPE: mse\n",
      "    MASK_ON: True\n",
      "    MASK_SIZE: 28\n",
      "    NMS_TH: 0.6\n",
      "    NORM: GN\n",
      "    NUM_BOX_CONVS: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CLS_CONVS: 4\n",
      "    NUM_MASK_CONVS: 4\n",
      "    NUM_SHARE_CONVS: 0\n",
      "    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz\n",
      "    POST_NMS_TOPK_TEST: 100\n",
      "    POST_NMS_TOPK_TRAIN: 100\n",
      "    POS_RADIUS: 1.5\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SIGMOID: True\n",
      "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
      "    THRESH_WITH_CTR: False\n",
      "    TOP_LEVELS: 2\n",
      "    TYPE_DEFORMABLE: DCNv1\n",
      "    USE_DEFORMABLE: False\n",
      "    USE_GCN_IN_MASK: False\n",
      "    USE_RELU: True\n",
      "    USE_SCALE: True\n",
      "    WHITEN: True\n",
      "  META_ARCHITECTURE: SOLOv2\n",
      "  MOBILENET: False\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_INTERVAL: 1\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  SOLOV2:\n",
      "    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]\n",
      "    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))\n",
      "    INSTANCE_CHANNELS: 512\n",
      "    INSTANCE_IN_CHANNELS: 256\n",
      "    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    LOSS:\n",
      "      DICE_WEIGHT: 3.0\n",
      "      FOCAL_ALPHA: 0.25\n",
      "      FOCAL_GAMMA: 2.0\n",
      "      FOCAL_USE_SIGMOID: True\n",
      "      FOCAL_WEIGHT: 1.0\n",
      "    MASK_CHANNELS: 128\n",
      "    MASK_IN_CHANNELS: 256\n",
      "    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    MASK_THR: 0.5\n",
      "    MAX_PER_IMG: 100\n",
      "    NMS_KERNEL: gaussian\n",
      "    NMS_PRE: 500\n",
      "    NMS_SIGMA: 2\n",
      "    NMS_TYPE: matrix\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 22\n",
      "    NUM_GRIDS: [40, 36, 24, 16, 12]\n",
      "    NUM_INSTANCE_CONVS: 4\n",
      "    NUM_KERNELS: 256\n",
      "    NUM_MASKS: 256\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THR: 0.1\n",
      "    SIGMA: 0.2\n",
      "    TYPE_DCN: DCN\n",
      "    UPDATE_THR: 0.05\n",
      "    USE_COORD_CONV: True\n",
      "    USE_DCN_IN_INSTANCE: False\n",
      "  TOP_MODULE:\n",
      "    DIM: 16\n",
      "    NAME: conv\n",
      "  VOVNET:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    CONV_BODY: V-39-eSE\n",
      "    NORM: FrozenBN\n",
      "    OUT_CHANNELS: 256\n",
      "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
      "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "OUTPUT_DIR: /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 200\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 6\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 4500\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (3000, 4000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 400\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[05/18 01:07:29 detectron2]: \u001b[0mFull config saved to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/config.yaml\n",
      "\u001b[32m[05/18 01:07:29 d2.utils.env]: \u001b[0mUsing a generated random seed 29436171\n",
      "\u001b[32m[05/18 01:07:32 d2.engine.defaults]: \u001b[0mModel:\n",
      "SOLOv2(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ins_head): SOLOv2InsHead(\n",
      "    (cate_tower): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (kernel_tower): Sequential(\n",
      "      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (cate_pred): Conv2d(512, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (mask_head): SOLOv2MaskHead(\n",
      "    (convs_all_levels): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "    )\n",
      "    (conv_pred): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/18 01:07:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/18 01:07:32 adet.data.dataset_mapper]: \u001b[0mRebuilding the augmentations. The previous augmentations will be overridden.\n",
      "\u001b[32m[05/18 01:07:32 adet.data.detection_utils]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/18 01:07:32 d2.data.datasets.coco]: \u001b[0mLoaded 10291 images in COCO format from /home/outletters/trashcan/Augmented/train_annotation.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/18 01:07:34 d2.data.datasets.coco]: \u001b[0mFiltered out 5 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n",
      "\u001b[32m[05/18 01:07:34 d2.data.build]: \u001b[0mRemoved 389 images with no usable annotations. 9902 images left.\n",
      "\u001b[32m[05/18 01:07:34 d2.data.build]: \u001b[0mDistribution of instances among all 22 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      rov      | 2628         |     plant     | 713          |  animal_fish  | 1575         |\n",
      "| animal_star.. | 530          | animal_shells | 508          |  animal_crab  | 598          |\n",
      "|  animal_eel   | 521          |  animal_etc   | 352          | trash_cloth.. | 153          |\n",
      "|  trash_pipe   | 302          | trash_bottle  | 268          |   trash_bag   | 727          |\n",
      "| trash_snack.. | 131          |   trash_can   | 846          |   trash_cup   | 125          |\n",
      "| trash_conta.. | 1091         | trash_unkno.. | 2203         | trash_branch  | 728          |\n",
      "| trash_wreck.. | 320          |  trash_tarp   | 228          |  trash_rope   | 210          |\n",
      "|   trash_net   | 112          |               |              |               |              |\n",
      "|     total     | 14869        |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/18 01:07:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[05/18 01:07:34 d2.data.common]: \u001b[0mSerializing 9902 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/18 01:07:34 d2.data.common]: \u001b[0mSerialized dataset takes 12.88 MiB\n",
      "\u001b[32m[05/18 01:07:36 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "\u001b[32m[05/18 01:07:36 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[32m[05/18 01:07:36 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone.bottom_up:\n",
      "| Names in Model    | Names in Checkpoint      | Shapes                                          |\n",
      "|:------------------|:-------------------------|:------------------------------------------------|\n",
      "| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\n",
      "| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\n",
      "\u001b[32m[05/18 01:07:36 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output3.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output4.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output5.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.cate_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.0.weight\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.10.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.3.weight\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.4.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.6.weight\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.7.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.cate_tower.9.weight\u001b[0m\n",
      "\u001b[34mins_head.kernel_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.0.weight\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.10.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.3.weight\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.4.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.6.weight\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.7.{bias, weight}\u001b[0m\n",
      "\u001b[34mins_head.kernel_tower.9.weight\u001b[0m\n",
      "\u001b[34mmask_head.conv_pred.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.conv_pred.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.0.conv0.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.0.conv0.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.1.conv0.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.1.conv0.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.2.conv0.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.2.conv0.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.2.conv1.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.2.conv1.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.3.conv0.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.3.conv0.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.3.conv1.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.3.conv1.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.3.conv2.0.weight\u001b[0m\n",
      "\u001b[34mmask_head.convs_all_levels.3.conv2.1.{bias, weight}\u001b[0m\n",
      "\u001b[32m[05/18 01:07:36 fvcore.common.checkpoint]: \u001b[0mThe checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mfc1000.{bias, weight}\u001b[0m\n",
      "  \u001b[35mstem.conv1.bias\u001b[0m\n",
      "Max iter:  4500 0\n",
      "\u001b[32m[05/18 01:07:36 adet.trainer]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/outletters/.local/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/outletters/.local/lib/python3.6/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/home/outletters/AdelaiDet/adet/modeling/solov2/solov2.py:198: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  hit_indices = ((gt_areas >= lower_bound) & (gt_areas <= upper_bound)).nonzero().flatten()\n",
      "/home/outletters/AdelaiDet/adet/modeling/solov2/solov2.py:379: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights = torch.tensor(weights.repeat(gts.shape[0],1)*gts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05/18 01:09:32 d2.utils.events]: \u001b[0m eta: 7:15:26  iter: 19  total_loss: 3.267  loss_ins: 2.72  loss_cate: 0.4682  time: 5.6961  data_time: 0.0360  lr: 4.8452e-05  max_mem: 9114M\n",
      "\u001b[32m[05/18 01:11:30 d2.utils.events]: \u001b[0m eta: 7:15:39  iter: 39  total_loss: 2.568  loss_ins: 2.056  loss_cate: 0.4981  time: 5.8071  data_time: 0.0220  lr: 9.8402e-05  max_mem: 9114M\n",
      "\u001b[32m[05/18 01:13:35 d2.utils.events]: \u001b[0m eta: 7:14:05  iter: 59  total_loss: 2.23  loss_ins: 1.788  loss_cate: 0.371  time: 5.8339  data_time: 0.0250  lr: 0.00014835  max_mem: 9114M\n",
      "\u001b[32m[05/18 01:15:33 d2.utils.events]: \u001b[0m eta: 7:13:48  iter: 79  total_loss: 2.138  loss_ins: 1.8  loss_cate: 0.3357  time: 5.8613  data_time: 0.0201  lr: 0.0001983  max_mem: 9114M\n",
      "\u001b[32m[05/18 01:17:29 d2.utils.events]: \u001b[0m eta: 7:10:35  iter: 99  total_loss: 1.744  loss_ins: 1.575  loss_cate: 0.2338  time: 5.8481  data_time: 0.0208  lr: 0.00024825  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:19:25 d2.utils.events]: \u001b[0m eta: 7:08:13  iter: 119  total_loss: 1.669  loss_ins: 1.418  loss_cate: 0.2365  time: 5.8405  data_time: 0.0206  lr: 0.0002982  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:21:21 d2.utils.events]: \u001b[0m eta: 7:05:46  iter: 139  total_loss: 1.54  loss_ins: 1.35  loss_cate: 0.2049  time: 5.8321  data_time: 0.0207  lr: 0.00034815  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:23:18 d2.utils.events]: \u001b[0m eta: 7:04:27  iter: 159  total_loss: 1.668  loss_ins: 1.508  loss_cate: 0.1547  time: 5.8347  data_time: 0.0254  lr: 0.0003981  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:25:16 d2.utils.events]: \u001b[0m eta: 7:02:46  iter: 179  total_loss: 1.472  loss_ins: 1.322  loss_cate: 0.1798  time: 5.8422  data_time: 0.0201  lr: 0.00044805  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:27:13 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0000199.pth\n",
      "\u001b[32m[05/18 01:27:13 d2.utils.events]: \u001b[0m eta: 7:00:58  iter: 199  total_loss: 1.65  loss_ins: 1.479  loss_cate: 0.1796  time: 5.8393  data_time: 0.0186  lr: 0.000498  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:29:07 d2.utils.events]: \u001b[0m eta: 6:58:54  iter: 219  total_loss: 1.677  loss_ins: 1.492  loss_cate: 0.2791  time: 5.8259  data_time: 0.0220  lr: 0.00054795  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:31:04 d2.utils.events]: \u001b[0m eta: 6:57:03  iter: 239  total_loss: 1.666  loss_ins: 1.394  loss_cate: 0.1929  time: 5.8294  data_time: 0.0212  lr: 0.0005979  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:32:59 d2.utils.events]: \u001b[0m eta: 6:54:49  iter: 259  total_loss: 1.747  loss_ins: 1.506  loss_cate: 0.1779  time: 5.8231  data_time: 0.0211  lr: 0.00064785  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:34:55 d2.utils.events]: \u001b[0m eta: 6:52:35  iter: 279  total_loss: 1.75  loss_ins: 1.481  loss_cate: 0.1781  time: 5.8211  data_time: 0.0222  lr: 0.0006978  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:36:53 d2.utils.events]: \u001b[0m eta: 6:51:10  iter: 299  total_loss: 1.623  loss_ins: 1.422  loss_cate: 0.1954  time: 5.8239  data_time: 0.0218  lr: 0.00074775  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:38:49 d2.utils.events]: \u001b[0m eta: 6:49:28  iter: 319  total_loss: 1.52  loss_ins: 1.346  loss_cate: 0.1762  time: 5.8230  data_time: 0.0211  lr: 0.0007977  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:40:46 d2.utils.events]: \u001b[0m eta: 6:47:15  iter: 339  total_loss: 1.486  loss_ins: 1.293  loss_cate: 0.1751  time: 5.8235  data_time: 0.0197  lr: 0.00084765  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:42:41 d2.utils.events]: \u001b[0m eta: 6:45:02  iter: 359  total_loss: 1.495  loss_ins: 1.299  loss_cate: 0.1472  time: 5.8204  data_time: 0.0214  lr: 0.0008976  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:44:37 d2.utils.events]: \u001b[0m eta: 6:42:48  iter: 379  total_loss: 1.367  loss_ins: 1.167  loss_cate: 0.1864  time: 5.8184  data_time: 0.0216  lr: 0.00094755  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:46:33 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0000399.pth\n",
      "\u001b[32m[05/18 01:46:33 d2.utils.events]: \u001b[0m eta: 6:40:47  iter: 399  total_loss: 1.345  loss_ins: 1.163  loss_cate: 0.1292  time: 5.8177  data_time: 0.0198  lr: 0.0009975  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:48:31 d2.utils.events]: \u001b[0m eta: 6:39:06  iter: 419  total_loss: 1.356  loss_ins: 1.171  loss_cate: 0.138  time: 5.8208  data_time: 0.0192  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:50:27 d2.utils.events]: \u001b[0m eta: 6:37:09  iter: 439  total_loss: 1.407  loss_ins: 1.218  loss_cate: 0.1666  time: 5.8205  data_time: 0.0217  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:52:23 d2.utils.events]: \u001b[0m eta: 6:35:15  iter: 459  total_loss: 1.14  loss_ins: 0.9969  loss_cate: 0.1688  time: 5.8177  data_time: 0.0202  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:54:16 d2.utils.events]: \u001b[0m eta: 6:33:00  iter: 479  total_loss: 1.314  loss_ins: 1.133  loss_cate: 0.1762  time: 5.8109  data_time: 0.0221  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:56:12 d2.utils.events]: \u001b[0m eta: 6:30:56  iter: 499  total_loss: 1.276  loss_ins: 1.089  loss_cate: 0.1582  time: 5.8108  data_time: 0.0195  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 01:58:06 d2.utils.events]: \u001b[0m eta: 6:28:47  iter: 519  total_loss: 1.189  loss_ins: 1.088  loss_cate: 0.1455  time: 5.8063  data_time: 0.0221  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:00:04 d2.utils.events]: \u001b[0m eta: 6:27:06  iter: 539  total_loss: 1.352  loss_ins: 1.229  loss_cate: 0.1448  time: 5.8102  data_time: 0.0188  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:02:02 d2.utils.events]: \u001b[0m eta: 6:25:12  iter: 559  total_loss: 1.238  loss_ins: 1.02  loss_cate: 0.1647  time: 5.8125  data_time: 0.0197  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:03:58 d2.utils.events]: \u001b[0m eta: 6:23:15  iter: 579  total_loss: 1.391  loss_ins: 1.093  loss_cate: 0.1812  time: 5.8121  data_time: 0.0213  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:05:54 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0000599.pth\n",
      "\u001b[32m[05/18 02:05:54 d2.utils.events]: \u001b[0m eta: 6:21:20  iter: 599  total_loss: 1.076  loss_ins: 0.9475  loss_cate: 0.1283  time: 5.8116  data_time: 0.0215  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:07:52 d2.utils.events]: \u001b[0m eta: 6:19:40  iter: 619  total_loss: 1.214  loss_ins: 0.9956  loss_cate: 0.1771  time: 5.8142  data_time: 0.0215  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:09:47 d2.utils.events]: \u001b[0m eta: 6:17:46  iter: 639  total_loss: 1.143  loss_ins: 0.9776  loss_cate: 0.1247  time: 5.8115  data_time: 0.0223  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:11:43 d2.utils.events]: \u001b[0m eta: 6:15:41  iter: 659  total_loss: 1.004  loss_ins: 0.9318  loss_cate: 0.1237  time: 5.8117  data_time: 0.0198  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:13:39 d2.utils.events]: \u001b[0m eta: 6:13:40  iter: 679  total_loss: 1.126  loss_ins: 0.9256  loss_cate: 0.14  time: 5.8104  data_time: 0.0185  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:15:33 d2.utils.events]: \u001b[0m eta: 6:11:41  iter: 699  total_loss: 1.047  loss_ins: 0.9463  loss_cate: 0.1192  time: 5.8078  data_time: 0.0211  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:17:30 d2.utils.events]: \u001b[0m eta: 6:09:49  iter: 719  total_loss: 0.9569  loss_ins: 0.7791  loss_cate: 0.1256  time: 5.8087  data_time: 0.0201  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:19:26 d2.utils.events]: \u001b[0m eta: 6:08:03  iter: 739  total_loss: 1.013  loss_ins: 0.8681  loss_cate: 0.1353  time: 5.8086  data_time: 0.0209  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:21:23 d2.utils.events]: \u001b[0m eta: 6:06:11  iter: 759  total_loss: 1.162  loss_ins: 0.9255  loss_cate: 0.1799  time: 5.8103  data_time: 0.0188  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:23:20 d2.utils.events]: \u001b[0m eta: 6:04:14  iter: 779  total_loss: 1.095  loss_ins: 0.9264  loss_cate: 0.1415  time: 5.8106  data_time: 0.0208  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:25:15 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0000799.pth\n",
      "\u001b[32m[05/18 02:25:16 d2.utils.events]: \u001b[0m eta: 6:02:20  iter: 799  total_loss: 1.217  loss_ins: 1.025  loss_cate: 0.1199  time: 5.8094  data_time: 0.0206  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:27:11 d2.utils.events]: \u001b[0m eta: 6:00:19  iter: 819  total_loss: 1.126  loss_ins: 0.9952  loss_cate: 0.1098  time: 5.8086  data_time: 0.0209  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:29:08 d2.utils.events]: \u001b[0m eta: 5:58:18  iter: 839  total_loss: 0.9458  loss_ins: 0.8045  loss_cate: 0.1068  time: 5.8095  data_time: 0.0216  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:31:05 d2.utils.events]: \u001b[0m eta: 5:56:24  iter: 859  total_loss: 0.9595  loss_ins: 0.8427  loss_cate: 0.1477  time: 5.8103  data_time: 0.0199  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:33:02 d2.utils.events]: \u001b[0m eta: 5:54:22  iter: 879  total_loss: 1.053  loss_ins: 0.8867  loss_cate: 0.1089  time: 5.8105  data_time: 0.0218  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:34:57 d2.utils.events]: \u001b[0m eta: 5:52:16  iter: 899  total_loss: 0.9315  loss_ins: 0.7573  loss_cate: 0.1458  time: 5.8099  data_time: 0.0200  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:36:53 d2.utils.events]: \u001b[0m eta: 5:50:19  iter: 919  total_loss: 1.082  loss_ins: 0.918  loss_cate: 0.1312  time: 5.8092  data_time: 0.0218  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:38:48 d2.utils.events]: \u001b[0m eta: 5:48:19  iter: 939  total_loss: 0.9306  loss_ins: 0.8215  loss_cate: 0.1121  time: 5.8075  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:40:45 d2.utils.events]: \u001b[0m eta: 5:46:17  iter: 959  total_loss: 0.8523  loss_ins: 0.7691  loss_cate: 0.0935  time: 5.8089  data_time: 0.0218  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:42:41 d2.utils.events]: \u001b[0m eta: 5:44:24  iter: 979  total_loss: 0.9802  loss_ins: 0.8365  loss_cate: 0.113  time: 5.8087  data_time: 0.0225  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:44:35 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0000999.pth\n",
      "\u001b[32m[05/18 02:44:36 d2.utils.events]: \u001b[0m eta: 5:42:20  iter: 999  total_loss: 1.001  loss_ins: 0.8661  loss_cate: 0.1225  time: 5.8065  data_time: 0.0184  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:46:31 d2.utils.events]: \u001b[0m eta: 5:40:27  iter: 1019  total_loss: 0.988  loss_ins: 0.8568  loss_cate: 0.1143  time: 5.8058  data_time: 0.0215  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:48:28 d2.utils.events]: \u001b[0m eta: 5:38:30  iter: 1039  total_loss: 1.037  loss_ins: 0.8536  loss_cate: 0.1264  time: 5.8067  data_time: 0.0193  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:50:26 d2.utils.events]: \u001b[0m eta: 5:36:35  iter: 1059  total_loss: 0.9824  loss_ins: 0.7901  loss_cate: 0.1187  time: 5.8084  data_time: 0.0199  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:52:19 d2.utils.events]: \u001b[0m eta: 5:34:20  iter: 1079  total_loss: 1.119  loss_ins: 0.9626  loss_cate: 0.1549  time: 5.8048  data_time: 0.0219  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:54:14 d2.utils.events]: \u001b[0m eta: 5:32:19  iter: 1099  total_loss: 0.9447  loss_ins: 0.8069  loss_cate: 0.1075  time: 5.8045  data_time: 0.0201  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:56:11 d2.utils.events]: \u001b[0m eta: 5:30:24  iter: 1119  total_loss: 0.8557  loss_ins: 0.7427  loss_cate: 0.1328  time: 5.8046  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 02:58:06 d2.utils.events]: \u001b[0m eta: 5:28:28  iter: 1139  total_loss: 0.8458  loss_ins: 0.7704  loss_cate: 0.09315  time: 5.8038  data_time: 0.0197  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:00:02 d2.utils.events]: \u001b[0m eta: 5:26:26  iter: 1159  total_loss: 0.8207  loss_ins: 0.7206  loss_cate: 0.1239  time: 5.8040  data_time: 0.0212  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:01:59 d2.utils.events]: \u001b[0m eta: 5:24:23  iter: 1179  total_loss: 0.884  loss_ins: 0.7667  loss_cate: 0.09589  time: 5.8046  data_time: 0.0217  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:03:56 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0001199.pth\n",
      "\u001b[32m[05/18 03:03:57 d2.utils.events]: \u001b[0m eta: 5:22:23  iter: 1199  total_loss: 0.8038  loss_ins: 0.631  loss_cate: 0.1075  time: 5.8058  data_time: 0.0206  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:05:55 d2.utils.events]: \u001b[0m eta: 5:20:26  iter: 1219  total_loss: 0.7494  loss_ins: 0.685  loss_cate: 0.1051  time: 5.8069  data_time: 0.0202  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:07:52 d2.utils.events]: \u001b[0m eta: 5:18:32  iter: 1239  total_loss: 1.104  loss_ins: 0.9034  loss_cate: 0.1206  time: 5.8078  data_time: 0.0205  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:09:47 d2.utils.events]: \u001b[0m eta: 5:16:31  iter: 1259  total_loss: 0.8297  loss_ins: 0.7348  loss_cate: 0.08275  time: 5.8065  data_time: 0.0240  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:11:44 d2.utils.events]: \u001b[0m eta: 5:14:39  iter: 1279  total_loss: 0.9988  loss_ins: 0.8604  loss_cate: 0.1071  time: 5.8078  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:13:40 d2.utils.events]: \u001b[0m eta: 5:12:26  iter: 1299  total_loss: 0.8795  loss_ins: 0.7023  loss_cate: 0.09454  time: 5.8077  data_time: 0.0234  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:15:34 d2.utils.events]: \u001b[0m eta: 5:10:20  iter: 1319  total_loss: 0.7905  loss_ins: 0.7032  loss_cate: 0.0972  time: 5.8055  data_time: 0.0191  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:17:30 d2.utils.events]: \u001b[0m eta: 5:08:23  iter: 1339  total_loss: 0.7833  loss_ins: 0.68  loss_cate: 0.08375  time: 5.8060  data_time: 0.0218  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:19:25 d2.utils.events]: \u001b[0m eta: 5:06:26  iter: 1359  total_loss: 0.9567  loss_ins: 0.79  loss_cate: 0.1075  time: 5.8051  data_time: 0.0198  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:21:24 d2.utils.events]: \u001b[0m eta: 5:04:34  iter: 1379  total_loss: 0.764  loss_ins: 0.6901  loss_cate: 0.08709  time: 5.8067  data_time: 0.0228  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:23:16 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0001399.pth\n",
      "\u001b[32m[05/18 03:23:17 d2.utils.events]: \u001b[0m eta: 5:02:35  iter: 1399  total_loss: 0.8375  loss_ins: 0.7385  loss_cate: 0.09143  time: 5.8040  data_time: 0.0204  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:25:12 d2.utils.events]: \u001b[0m eta: 5:00:34  iter: 1419  total_loss: 0.8662  loss_ins: 0.7879  loss_cate: 0.105  time: 5.8037  data_time: 0.0204  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:27:10 d2.utils.events]: \u001b[0m eta: 4:58:38  iter: 1439  total_loss: 0.8942  loss_ins: 0.7654  loss_cate: 0.1268  time: 5.8049  data_time: 0.0200  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:29:07 d2.utils.events]: \u001b[0m eta: 4:56:41  iter: 1459  total_loss: 0.7594  loss_ins: 0.6725  loss_cate: 0.07957  time: 5.8055  data_time: 0.0195  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:31:02 d2.utils.events]: \u001b[0m eta: 4:54:51  iter: 1479  total_loss: 0.8274  loss_ins: 0.7373  loss_cate: 0.07696  time: 5.8047  data_time: 0.0204  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:32:58 d2.utils.events]: \u001b[0m eta: 4:52:58  iter: 1499  total_loss: 0.686  loss_ins: 0.5832  loss_cate: 0.08774  time: 5.8045  data_time: 0.0221  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:34:54 d2.utils.events]: \u001b[0m eta: 4:51:03  iter: 1519  total_loss: 0.7573  loss_ins: 0.6523  loss_cate: 0.09026  time: 5.8047  data_time: 0.0206  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:36:51 d2.utils.events]: \u001b[0m eta: 4:48:58  iter: 1539  total_loss: 0.7191  loss_ins: 0.6562  loss_cate: 0.07153  time: 5.8048  data_time: 0.0198  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:38:45 d2.utils.events]: \u001b[0m eta: 4:46:58  iter: 1559  total_loss: 0.82  loss_ins: 0.7295  loss_cate: 0.07911  time: 5.8039  data_time: 0.0205  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:40:42 d2.utils.events]: \u001b[0m eta: 4:45:01  iter: 1579  total_loss: 0.74  loss_ins: 0.6529  loss_cate: 0.1124  time: 5.8044  data_time: 0.0230  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:42:38 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0001599.pth\n",
      "\u001b[32m[05/18 03:42:39 d2.utils.events]: \u001b[0m eta: 4:43:00  iter: 1599  total_loss: 0.7569  loss_ins: 0.6454  loss_cate: 0.09549  time: 5.8042  data_time: 0.0226  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:44:36 d2.utils.events]: \u001b[0m eta: 4:41:00  iter: 1619  total_loss: 0.7813  loss_ins: 0.6846  loss_cate: 0.1166  time: 5.8047  data_time: 0.0224  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:46:31 d2.utils.events]: \u001b[0m eta: 4:39:01  iter: 1639  total_loss: 0.8137  loss_ins: 0.6843  loss_cate: 0.08323  time: 5.8045  data_time: 0.0230  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:48:27 d2.utils.events]: \u001b[0m eta: 4:37:01  iter: 1659  total_loss: 0.7257  loss_ins: 0.5781  loss_cate: 0.08457  time: 5.8043  data_time: 0.0234  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:50:23 d2.utils.events]: \u001b[0m eta: 4:35:03  iter: 1679  total_loss: 0.6755  loss_ins: 0.5832  loss_cate: 0.08743  time: 5.8043  data_time: 0.0185  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:52:18 d2.utils.events]: \u001b[0m eta: 4:33:04  iter: 1699  total_loss: 0.6963  loss_ins: 0.6273  loss_cate: 0.07485  time: 5.8032  data_time: 0.0199  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:54:14 d2.utils.events]: \u001b[0m eta: 4:31:04  iter: 1719  total_loss: 0.8792  loss_ins: 0.7279  loss_cate: 0.1057  time: 5.8033  data_time: 0.0225  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:56:10 d2.utils.events]: \u001b[0m eta: 4:29:07  iter: 1739  total_loss: 0.8763  loss_ins: 0.7562  loss_cate: 0.08777  time: 5.8031  data_time: 0.0223  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 03:58:05 d2.utils.events]: \u001b[0m eta: 4:27:09  iter: 1759  total_loss: 0.7479  loss_ins: 0.6616  loss_cate: 0.09457  time: 5.8025  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:00:00 d2.utils.events]: \u001b[0m eta: 4:25:10  iter: 1779  total_loss: 0.7685  loss_ins: 0.6464  loss_cate: 0.08961  time: 5.8021  data_time: 0.0207  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:01:56 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0001799.pth\n",
      "\u001b[32m[05/18 04:01:57 d2.utils.events]: \u001b[0m eta: 4:23:03  iter: 1799  total_loss: 0.6918  loss_ins: 0.6288  loss_cate: 0.07239  time: 5.8021  data_time: 0.0231  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:03:51 d2.utils.events]: \u001b[0m eta: 4:21:05  iter: 1819  total_loss: 0.7534  loss_ins: 0.6607  loss_cate: 0.07333  time: 5.8013  data_time: 0.0218  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:05:49 d2.utils.events]: \u001b[0m eta: 4:19:13  iter: 1839  total_loss: 0.7972  loss_ins: 0.7107  loss_cate: 0.08719  time: 5.8021  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:07:43 d2.utils.events]: \u001b[0m eta: 4:17:11  iter: 1859  total_loss: 0.7434  loss_ins: 0.648  loss_cate: 0.08806  time: 5.8008  data_time: 0.0219  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:09:39 d2.utils.events]: \u001b[0m eta: 4:15:14  iter: 1879  total_loss: 0.6697  loss_ins: 0.5792  loss_cate: 0.08065  time: 5.8009  data_time: 0.0210  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:11:33 d2.utils.events]: \u001b[0m eta: 4:13:17  iter: 1899  total_loss: 0.746  loss_ins: 0.6536  loss_cate: 0.09912  time: 5.7997  data_time: 0.0229  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:13:30 d2.utils.events]: \u001b[0m eta: 4:11:20  iter: 1919  total_loss: 0.6848  loss_ins: 0.5629  loss_cate: 0.0885  time: 5.8002  data_time: 0.0205  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:15:24 d2.utils.events]: \u001b[0m eta: 4:09:24  iter: 1939  total_loss: 0.7249  loss_ins: 0.6459  loss_cate: 0.08511  time: 5.7992  data_time: 0.0206  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:17:20 d2.utils.events]: \u001b[0m eta: 4:07:27  iter: 1959  total_loss: 0.75  loss_ins: 0.6575  loss_cate: 0.07317  time: 5.7992  data_time: 0.0241  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:19:16 d2.utils.events]: \u001b[0m eta: 4:05:23  iter: 1979  total_loss: 0.8029  loss_ins: 0.7302  loss_cate: 0.07887  time: 5.7994  data_time: 0.0199  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:21:13 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0001999.pth\n",
      "\u001b[32m[05/18 04:21:13 d2.utils.events]: \u001b[0m eta: 4:03:34  iter: 1999  total_loss: 0.7083  loss_ins: 0.649  loss_cate: 0.0694  time: 5.7997  data_time: 0.0216  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:23:11 d2.utils.events]: \u001b[0m eta: 4:01:38  iter: 2019  total_loss: 0.6967  loss_ins: 0.5749  loss_cate: 0.07045  time: 5.8003  data_time: 0.0222  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:25:08 d2.utils.events]: \u001b[0m eta: 3:59:40  iter: 2039  total_loss: 0.6605  loss_ins: 0.5524  loss_cate: 0.06475  time: 5.8008  data_time: 0.0219  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:27:06 d2.utils.events]: \u001b[0m eta: 3:57:44  iter: 2059  total_loss: 0.7285  loss_ins: 0.6449  loss_cate: 0.09184  time: 5.8018  data_time: 0.0192  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:28:57 d2.utils.events]: \u001b[0m eta: 3:55:52  iter: 2079  total_loss: 0.6206  loss_ins: 0.5472  loss_cate: 0.05921  time: 5.7996  data_time: 0.0234  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:30:55 d2.utils.events]: \u001b[0m eta: 3:53:57  iter: 2099  total_loss: 0.626  loss_ins: 0.5579  loss_cate: 0.06972  time: 5.8004  data_time: 0.0220  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:32:48 d2.utils.events]: \u001b[0m eta: 3:51:54  iter: 2119  total_loss: 0.6832  loss_ins: 0.5773  loss_cate: 0.07532  time: 5.7988  data_time: 0.0241  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:34:44 d2.utils.events]: \u001b[0m eta: 3:49:54  iter: 2139  total_loss: 0.6636  loss_ins: 0.5761  loss_cate: 0.08561  time: 5.7989  data_time: 0.0216  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:36:37 d2.utils.events]: \u001b[0m eta: 3:47:57  iter: 2159  total_loss: 0.6187  loss_ins: 0.5638  loss_cate: 0.05218  time: 5.7977  data_time: 0.0207  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:38:33 d2.utils.events]: \u001b[0m eta: 3:46:01  iter: 2179  total_loss: 0.7175  loss_ins: 0.6398  loss_cate: 0.07374  time: 5.7973  data_time: 0.0217  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:40:29 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0002199.pth\n",
      "\u001b[32m[05/18 04:40:30 d2.utils.events]: \u001b[0m eta: 3:44:03  iter: 2199  total_loss: 0.5969  loss_ins: 0.532  loss_cate: 0.08002  time: 5.7978  data_time: 0.0193  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:42:27 d2.utils.events]: \u001b[0m eta: 3:42:07  iter: 2219  total_loss: 0.6558  loss_ins: 0.5612  loss_cate: 0.07405  time: 5.7981  data_time: 0.0197  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:44:22 d2.utils.events]: \u001b[0m eta: 3:40:09  iter: 2239  total_loss: 0.6614  loss_ins: 0.5837  loss_cate: 0.07289  time: 5.7979  data_time: 0.0212  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:46:19 d2.utils.events]: \u001b[0m eta: 3:38:14  iter: 2259  total_loss: 0.5588  loss_ins: 0.4983  loss_cate: 0.05939  time: 5.7982  data_time: 0.0196  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:48:17 d2.utils.events]: \u001b[0m eta: 3:36:18  iter: 2279  total_loss: 0.5753  loss_ins: 0.5168  loss_cate: 0.06288  time: 5.7991  data_time: 0.0221  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:50:14 d2.utils.events]: \u001b[0m eta: 3:34:21  iter: 2299  total_loss: 0.5635  loss_ins: 0.4684  loss_cate: 0.05185  time: 5.7993  data_time: 0.0207  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:52:09 d2.utils.events]: \u001b[0m eta: 3:32:29  iter: 2319  total_loss: 0.5499  loss_ins: 0.4699  loss_cate: 0.07314  time: 5.7990  data_time: 0.0206  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:54:05 d2.utils.events]: \u001b[0m eta: 3:30:35  iter: 2339  total_loss: 0.627  loss_ins: 0.5343  loss_cate: 0.07258  time: 5.7991  data_time: 0.0224  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:55:59 d2.utils.events]: \u001b[0m eta: 3:28:41  iter: 2359  total_loss: 0.6336  loss_ins: 0.5739  loss_cate: 0.05286  time: 5.7984  data_time: 0.0206  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:57:57 d2.utils.events]: \u001b[0m eta: 3:26:43  iter: 2379  total_loss: 0.5563  loss_ins: 0.511  loss_cate: 0.05703  time: 5.7989  data_time: 0.0211  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 04:59:52 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0002399.pth\n",
      "\u001b[32m[05/18 04:59:52 d2.utils.events]: \u001b[0m eta: 3:24:48  iter: 2399  total_loss: 0.5967  loss_ins: 0.5407  loss_cate: 0.0597  time: 5.7985  data_time: 0.0198  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:01:45 d2.utils.events]: \u001b[0m eta: 3:22:51  iter: 2419  total_loss: 0.6074  loss_ins: 0.5333  loss_cate: 0.05406  time: 5.7973  data_time: 0.0201  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:03:41 d2.utils.events]: \u001b[0m eta: 3:20:50  iter: 2439  total_loss: 0.5129  loss_ins: 0.4196  loss_cate: 0.05344  time: 5.7972  data_time: 0.0222  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:05:37 d2.utils.events]: \u001b[0m eta: 3:18:52  iter: 2459  total_loss: 0.6782  loss_ins: 0.5952  loss_cate: 0.04939  time: 5.7970  data_time: 0.0199  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:07:33 d2.utils.events]: \u001b[0m eta: 3:16:55  iter: 2479  total_loss: 0.5946  loss_ins: 0.4816  loss_cate: 0.07644  time: 5.7973  data_time: 0.0190  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:09:29 d2.utils.events]: \u001b[0m eta: 3:14:55  iter: 2499  total_loss: 0.4941  loss_ins: 0.3994  loss_cate: 0.05265  time: 5.7971  data_time: 0.0204  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:11:25 d2.utils.events]: \u001b[0m eta: 3:12:55  iter: 2519  total_loss: 0.6088  loss_ins: 0.5384  loss_cate: 0.06798  time: 5.7971  data_time: 0.0228  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:13:22 d2.utils.events]: \u001b[0m eta: 3:11:04  iter: 2539  total_loss: 0.5455  loss_ins: 0.4785  loss_cate: 0.06258  time: 5.7975  data_time: 0.0203  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:15:20 d2.utils.events]: \u001b[0m eta: 3:09:12  iter: 2559  total_loss: 0.5948  loss_ins: 0.5119  loss_cate: 0.06284  time: 5.7985  data_time: 0.0225  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:17:16 d2.utils.events]: \u001b[0m eta: 3:07:13  iter: 2579  total_loss: 0.6113  loss_ins: 0.5392  loss_cate: 0.06475  time: 5.7985  data_time: 0.0226  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:19:12 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0002599.pth\n",
      "\u001b[32m[05/18 05:19:12 d2.utils.events]: \u001b[0m eta: 3:05:18  iter: 2599  total_loss: 0.5115  loss_ins: 0.4473  loss_cate: 0.06257  time: 5.7982  data_time: 0.0190  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:21:10 d2.utils.events]: \u001b[0m eta: 3:03:22  iter: 2619  total_loss: 0.7018  loss_ins: 0.6233  loss_cate: 0.0669  time: 5.7990  data_time: 0.0214  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:23:06 d2.utils.events]: \u001b[0m eta: 3:01:24  iter: 2639  total_loss: 0.6416  loss_ins: 0.6073  loss_cate: 0.05588  time: 5.7989  data_time: 0.0196  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:25:03 d2.utils.events]: \u001b[0m eta: 2:59:28  iter: 2659  total_loss: 0.5715  loss_ins: 0.4921  loss_cate: 0.08266  time: 5.7991  data_time: 0.0203  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:26:58 d2.utils.events]: \u001b[0m eta: 2:57:30  iter: 2679  total_loss: 0.5562  loss_ins: 0.4863  loss_cate: 0.06004  time: 5.7987  data_time: 0.0204  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:28:54 d2.utils.events]: \u001b[0m eta: 2:55:33  iter: 2699  total_loss: 0.542  loss_ins: 0.494  loss_cate: 0.05537  time: 5.7989  data_time: 0.0219  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:30:51 d2.utils.events]: \u001b[0m eta: 2:53:38  iter: 2719  total_loss: 0.6372  loss_ins: 0.5749  loss_cate: 0.04643  time: 5.7991  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:32:46 d2.utils.events]: \u001b[0m eta: 2:51:37  iter: 2739  total_loss: 0.6272  loss_ins: 0.5649  loss_cate: 0.06029  time: 5.7987  data_time: 0.0196  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:34:43 d2.utils.events]: \u001b[0m eta: 2:49:42  iter: 2759  total_loss: 0.6161  loss_ins: 0.5635  loss_cate: 0.05106  time: 5.7992  data_time: 0.0204  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:36:39 d2.utils.events]: \u001b[0m eta: 2:47:44  iter: 2779  total_loss: 0.5637  loss_ins: 0.5014  loss_cate: 0.04698  time: 5.7993  data_time: 0.0240  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:38:36 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0002799.pth\n",
      "\u001b[32m[05/18 05:38:37 d2.utils.events]: \u001b[0m eta: 2:45:49  iter: 2799  total_loss: 0.5974  loss_ins: 0.5504  loss_cate: 0.05598  time: 5.7996  data_time: 0.0199  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:40:33 d2.utils.events]: \u001b[0m eta: 2:43:53  iter: 2819  total_loss: 0.4829  loss_ins: 0.4414  loss_cate: 0.03817  time: 5.7998  data_time: 0.0224  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:42:28 d2.utils.events]: \u001b[0m eta: 2:41:54  iter: 2839  total_loss: 0.6763  loss_ins: 0.5969  loss_cate: 0.08884  time: 5.7995  data_time: 0.0195  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:44:25 d2.utils.events]: \u001b[0m eta: 2:39:59  iter: 2859  total_loss: 0.5941  loss_ins: 0.5314  loss_cate: 0.06973  time: 5.7998  data_time: 0.0197  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:46:20 d2.utils.events]: \u001b[0m eta: 2:38:01  iter: 2879  total_loss: 0.4391  loss_ins: 0.395  loss_cate: 0.04273  time: 5.7994  data_time: 0.0198  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:48:17 d2.utils.events]: \u001b[0m eta: 2:36:05  iter: 2899  total_loss: 0.609  loss_ins: 0.5547  loss_cate: 0.05584  time: 5.7996  data_time: 0.0188  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:50:13 d2.utils.events]: \u001b[0m eta: 2:34:07  iter: 2919  total_loss: 0.6672  loss_ins: 0.6144  loss_cate: 0.06252  time: 5.7996  data_time: 0.0209  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:52:09 d2.utils.events]: \u001b[0m eta: 2:32:10  iter: 2939  total_loss: 0.703  loss_ins: 0.656  loss_cate: 0.05773  time: 5.7998  data_time: 0.0194  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:54:05 d2.utils.events]: \u001b[0m eta: 2:30:12  iter: 2959  total_loss: 0.5831  loss_ins: 0.5388  loss_cate: 0.05033  time: 5.7998  data_time: 0.0210  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:56:01 d2.utils.events]: \u001b[0m eta: 2:28:16  iter: 2979  total_loss: 0.6968  loss_ins: 0.6183  loss_cate: 0.06235  time: 5.7995  data_time: 0.0201  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:57:58 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0002999.pth\n",
      "\u001b[32m[05/18 05:57:59 d2.utils.events]: \u001b[0m eta: 2:26:18  iter: 2999  total_loss: 0.439  loss_ins: 0.3866  loss_cate: 0.0454  time: 5.8000  data_time: 0.0216  lr: 0.001  max_mem: 9183M\n",
      "\u001b[32m[05/18 05:59:55 d2.utils.events]: \u001b[0m eta: 2:24:21  iter: 3019  total_loss: 0.5222  loss_ins: 0.4895  loss_cate: 0.04601  time: 5.8001  data_time: 0.0190  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:01:51 d2.utils.events]: \u001b[0m eta: 2:22:25  iter: 3039  total_loss: 0.5597  loss_ins: 0.5146  loss_cate: 0.05453  time: 5.8002  data_time: 0.0195  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:03:48 d2.utils.events]: \u001b[0m eta: 2:20:25  iter: 3059  total_loss: 0.5417  loss_ins: 0.4675  loss_cate: 0.04958  time: 5.8003  data_time: 0.0210  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:05:44 d2.utils.events]: \u001b[0m eta: 2:18:29  iter: 3079  total_loss: 0.5099  loss_ins: 0.4218  loss_cate: 0.03943  time: 5.8003  data_time: 0.0192  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:07:39 d2.utils.events]: \u001b[0m eta: 2:16:30  iter: 3099  total_loss: 0.4889  loss_ins: 0.4351  loss_cate: 0.03703  time: 5.8002  data_time: 0.0205  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:09:35 d2.utils.events]: \u001b[0m eta: 2:14:34  iter: 3119  total_loss: 0.4836  loss_ins: 0.4338  loss_cate: 0.04572  time: 5.8001  data_time: 0.0215  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:11:31 d2.utils.events]: \u001b[0m eta: 2:12:36  iter: 3139  total_loss: 0.4253  loss_ins: 0.3836  loss_cate: 0.0353  time: 5.7999  data_time: 0.0189  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:13:27 d2.utils.events]: \u001b[0m eta: 2:10:40  iter: 3159  total_loss: 0.367  loss_ins: 0.3259  loss_cate: 0.03671  time: 5.7999  data_time: 0.0206  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:15:23 d2.utils.events]: \u001b[0m eta: 2:08:44  iter: 3179  total_loss: 0.4881  loss_ins: 0.4278  loss_cate: 0.04159  time: 5.8000  data_time: 0.0216  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:17:20 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0003199.pth\n",
      "\u001b[32m[05/18 06:17:21 d2.utils.events]: \u001b[0m eta: 2:06:47  iter: 3199  total_loss: 0.5651  loss_ins: 0.4799  loss_cate: 0.05184  time: 5.8003  data_time: 0.0216  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:19:16 d2.utils.events]: \u001b[0m eta: 2:04:49  iter: 3219  total_loss: 0.4954  loss_ins: 0.4521  loss_cate: 0.04597  time: 5.7999  data_time: 0.0219  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:21:12 d2.utils.events]: \u001b[0m eta: 2:02:54  iter: 3239  total_loss: 0.4704  loss_ins: 0.4148  loss_cate: 0.04549  time: 5.8000  data_time: 0.0203  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:23:10 d2.utils.events]: \u001b[0m eta: 2:00:57  iter: 3259  total_loss: 0.4887  loss_ins: 0.4108  loss_cate: 0.04296  time: 5.8005  data_time: 0.0213  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:25:05 d2.utils.events]: \u001b[0m eta: 1:58:59  iter: 3279  total_loss: 0.494  loss_ins: 0.4668  loss_cate: 0.0378  time: 5.8002  data_time: 0.0185  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:27:01 d2.utils.events]: \u001b[0m eta: 1:57:03  iter: 3299  total_loss: 0.3849  loss_ins: 0.3554  loss_cate: 0.0355  time: 5.8004  data_time: 0.0240  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:28:58 d2.utils.events]: \u001b[0m eta: 1:55:07  iter: 3319  total_loss: 0.5501  loss_ins: 0.5138  loss_cate: 0.04103  time: 5.8008  data_time: 0.0193  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:30:53 d2.utils.events]: \u001b[0m eta: 1:53:08  iter: 3339  total_loss: 0.5099  loss_ins: 0.4421  loss_cate: 0.03582  time: 5.8004  data_time: 0.0187  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:32:48 d2.utils.events]: \u001b[0m eta: 1:51:11  iter: 3359  total_loss: 0.4586  loss_ins: 0.433  loss_cate: 0.03983  time: 5.7999  data_time: 0.0202  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:34:46 d2.utils.events]: \u001b[0m eta: 1:49:13  iter: 3379  total_loss: 0.3741  loss_ins: 0.3471  loss_cate: 0.04019  time: 5.8005  data_time: 0.0210  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:36:42 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0003399.pth\n",
      "\u001b[32m[05/18 06:36:43 d2.utils.events]: \u001b[0m eta: 1:47:16  iter: 3399  total_loss: 0.4471  loss_ins: 0.4149  loss_cate: 0.03312  time: 5.8007  data_time: 0.0216  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:38:38 d2.utils.events]: \u001b[0m eta: 1:45:18  iter: 3419  total_loss: 0.407  loss_ins: 0.3799  loss_cate: 0.02938  time: 5.8004  data_time: 0.0217  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:40:35 d2.utils.events]: \u001b[0m eta: 1:43:22  iter: 3439  total_loss: 0.4636  loss_ins: 0.4208  loss_cate: 0.03503  time: 5.8007  data_time: 0.0217  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:42:29 d2.utils.events]: \u001b[0m eta: 1:41:23  iter: 3459  total_loss: 0.426  loss_ins: 0.3805  loss_cate: 0.04512  time: 5.8001  data_time: 0.0193  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:44:26 d2.utils.events]: \u001b[0m eta: 1:39:27  iter: 3479  total_loss: 0.4461  loss_ins: 0.3672  loss_cate: 0.0385  time: 5.8004  data_time: 0.0210  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:46:21 d2.utils.events]: \u001b[0m eta: 1:37:30  iter: 3499  total_loss: 0.5109  loss_ins: 0.4788  loss_cate: 0.03455  time: 5.8001  data_time: 0.0213  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:48:18 d2.utils.events]: \u001b[0m eta: 1:35:34  iter: 3519  total_loss: 0.4164  loss_ins: 0.3873  loss_cate: 0.02744  time: 5.8004  data_time: 0.0232  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:50:13 d2.utils.events]: \u001b[0m eta: 1:33:36  iter: 3539  total_loss: 0.4531  loss_ins: 0.4098  loss_cate: 0.03553  time: 5.8000  data_time: 0.0208  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:52:08 d2.utils.events]: \u001b[0m eta: 1:31:36  iter: 3559  total_loss: 0.4612  loss_ins: 0.4082  loss_cate: 0.03647  time: 5.7997  data_time: 0.0197  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:54:04 d2.utils.events]: \u001b[0m eta: 1:29:39  iter: 3579  total_loss: 0.4217  loss_ins: 0.3942  loss_cate: 0.03331  time: 5.7998  data_time: 0.0195  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:56:02 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0003599.pth\n",
      "\u001b[32m[05/18 06:56:02 d2.utils.events]: \u001b[0m eta: 1:27:43  iter: 3599  total_loss: 0.4129  loss_ins: 0.3772  loss_cate: 0.0401  time: 5.8002  data_time: 0.0230  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:58:00 d2.utils.events]: \u001b[0m eta: 1:25:46  iter: 3619  total_loss: 0.4216  loss_ins: 0.3883  loss_cate: 0.03366  time: 5.8005  data_time: 0.0219  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 06:59:58 d2.utils.events]: \u001b[0m eta: 1:23:51  iter: 3639  total_loss: 0.4791  loss_ins: 0.4437  loss_cate: 0.03271  time: 5.8011  data_time: 0.0228  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:01:52 d2.utils.events]: \u001b[0m eta: 1:21:54  iter: 3659  total_loss: 0.3741  loss_ins: 0.3405  loss_cate: 0.03398  time: 5.8007  data_time: 0.0205  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:03:48 d2.utils.events]: \u001b[0m eta: 1:19:57  iter: 3679  total_loss: 0.4518  loss_ins: 0.4252  loss_cate: 0.03496  time: 5.8005  data_time: 0.0218  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:05:46 d2.utils.events]: \u001b[0m eta: 1:18:02  iter: 3699  total_loss: 0.3092  loss_ins: 0.2873  loss_cate: 0.0302  time: 5.8012  data_time: 0.0212  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:07:42 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 3719  total_loss: 0.3524  loss_ins: 0.3177  loss_cate: 0.03573  time: 5.8012  data_time: 0.0202  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:09:37 d2.utils.events]: \u001b[0m eta: 1:14:08  iter: 3739  total_loss: 0.5074  loss_ins: 0.4603  loss_cate: 0.03465  time: 5.8009  data_time: 0.0261  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:11:33 d2.utils.events]: \u001b[0m eta: 1:12:10  iter: 3759  total_loss: 0.4009  loss_ins: 0.3517  loss_cate: 0.03893  time: 5.8009  data_time: 0.0214  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:13:29 d2.utils.events]: \u001b[0m eta: 1:10:13  iter: 3779  total_loss: 0.3866  loss_ins: 0.3182  loss_cate: 0.0318  time: 5.8008  data_time: 0.0217  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:15:26 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0003799.pth\n",
      "\u001b[32m[05/18 07:15:27 d2.utils.events]: \u001b[0m eta: 1:08:15  iter: 3799  total_loss: 0.3467  loss_ins: 0.31  loss_cate: 0.02985  time: 5.8011  data_time: 0.0197  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:17:22 d2.utils.events]: \u001b[0m eta: 1:06:19  iter: 3819  total_loss: 0.4025  loss_ins: 0.3436  loss_cate: 0.03258  time: 5.8010  data_time: 0.0202  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:19:18 d2.utils.events]: \u001b[0m eta: 1:04:22  iter: 3839  total_loss: 0.4642  loss_ins: 0.4239  loss_cate: 0.03388  time: 5.8010  data_time: 0.0202  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:21:14 d2.utils.events]: \u001b[0m eta: 1:02:24  iter: 3859  total_loss: 0.4413  loss_ins: 0.419  loss_cate: 0.03217  time: 5.8008  data_time: 0.0216  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:23:07 d2.utils.events]: \u001b[0m eta: 1:00:27  iter: 3879  total_loss: 0.337  loss_ins: 0.3117  loss_cate: 0.02899  time: 5.8001  data_time: 0.0206  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:25:04 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 3899  total_loss: 0.3896  loss_ins: 0.3648  loss_cate: 0.03392  time: 5.8002  data_time: 0.0200  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:26:59 d2.utils.events]: \u001b[0m eta: 0:56:34  iter: 3919  total_loss: 0.3933  loss_ins: 0.3298  loss_cate: 0.03633  time: 5.8001  data_time: 0.0226  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:28:57 d2.utils.events]: \u001b[0m eta: 0:54:37  iter: 3939  total_loss: 0.5053  loss_ins: 0.459  loss_cate: 0.0374  time: 5.8006  data_time: 0.0202  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:30:54 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 3959  total_loss: 0.5201  loss_ins: 0.4787  loss_cate: 0.03807  time: 5.8008  data_time: 0.0203  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:32:48 d2.utils.events]: \u001b[0m eta: 0:50:43  iter: 3979  total_loss: 0.4064  loss_ins: 0.366  loss_cate: 0.03374  time: 5.8003  data_time: 0.0189  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:34:44 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0003999.pth\n",
      "\u001b[32m[05/18 07:34:45 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 3999  total_loss: 0.3948  loss_ins: 0.3777  loss_cate: 0.02991  time: 5.8003  data_time: 0.0201  lr: 0.0001  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:36:41 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 4019  total_loss: 0.4168  loss_ins: 0.3765  loss_cate: 0.0331  time: 5.8003  data_time: 0.0230  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:38:36 d2.utils.events]: \u001b[0m eta: 0:44:50  iter: 4039  total_loss: 0.4143  loss_ins: 0.3897  loss_cate: 0.0279  time: 5.8002  data_time: 0.0196  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:40:33 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 4059  total_loss: 0.3991  loss_ins: 0.3687  loss_cate: 0.03584  time: 5.8003  data_time: 0.0204  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:42:31 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 4079  total_loss: 0.3645  loss_ins: 0.3335  loss_cate: 0.02711  time: 5.8008  data_time: 0.0216  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:44:29 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 4099  total_loss: 0.4392  loss_ins: 0.4  loss_cate: 0.03455  time: 5.8013  data_time: 0.0199  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:46:25 d2.utils.events]: \u001b[0m eta: 0:37:03  iter: 4119  total_loss: 0.4443  loss_ins: 0.4137  loss_cate: 0.03048  time: 5.8012  data_time: 0.0203  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:48:22 d2.utils.events]: \u001b[0m eta: 0:35:07  iter: 4139  total_loss: 0.4182  loss_ins: 0.3951  loss_cate: 0.02725  time: 5.8014  data_time: 0.0212  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:50:19 d2.utils.events]: \u001b[0m eta: 0:33:10  iter: 4159  total_loss: 0.3997  loss_ins: 0.3657  loss_cate: 0.03121  time: 5.8018  data_time: 0.0210  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:52:17 d2.utils.events]: \u001b[0m eta: 0:31:13  iter: 4179  total_loss: 0.4141  loss_ins: 0.3743  loss_cate: 0.03302  time: 5.8021  data_time: 0.0212  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:54:14 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0004199.pth\n",
      "\u001b[32m[05/18 07:54:14 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 4199  total_loss: 0.3904  loss_ins: 0.3485  loss_cate: 0.03231  time: 5.8023  data_time: 0.0204  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:56:13 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 4219  total_loss: 0.4721  loss_ins: 0.4279  loss_cate: 0.03976  time: 5.8029  data_time: 0.0198  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 07:58:09 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 4239  total_loss: 0.5031  loss_ins: 0.4624  loss_cate: 0.04202  time: 5.8029  data_time: 0.0212  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:00:06 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 4259  total_loss: 0.3886  loss_ins: 0.3509  loss_cate: 0.02499  time: 5.8031  data_time: 0.0212  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:02:01 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 4279  total_loss: 0.4593  loss_ins: 0.4333  loss_cate: 0.03008  time: 5.8029  data_time: 0.0215  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:03:57 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 4299  total_loss: 0.4596  loss_ins: 0.4207  loss_cate: 0.03698  time: 5.8029  data_time: 0.0188  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:05:53 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 4319  total_loss: 0.3827  loss_ins: 0.3422  loss_cate: 0.03603  time: 5.8029  data_time: 0.0255  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:07:50 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 4339  total_loss: 0.4359  loss_ins: 0.364  loss_cate: 0.0367  time: 5.8030  data_time: 0.0221  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:09:47 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 4359  total_loss: 0.4261  loss_ins: 0.3955  loss_cate: 0.03777  time: 5.8032  data_time: 0.0202  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:11:44 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 4379  total_loss: 0.3971  loss_ins: 0.3695  loss_cate: 0.03039  time: 5.8034  data_time: 0.0206  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:13:37 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_0004399.pth\n",
      "\u001b[32m[05/18 08:13:38 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 4399  total_loss: 0.4228  loss_ins: 0.3771  loss_cate: 0.03138  time: 5.8029  data_time: 0.0202  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:15:34 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 4419  total_loss: 0.5028  loss_ins: 0.447  loss_cate: 0.03838  time: 5.8029  data_time: 0.0216  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:17:28 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 4439  total_loss: 0.441  loss_ins: 0.4018  loss_cate: 0.03875  time: 5.8024  data_time: 0.0198  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:19:26 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 4459  total_loss: 0.4605  loss_ins: 0.4263  loss_cate: 0.03502  time: 5.8027  data_time: 0.0212  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:21:23 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 4479  total_loss: 0.525  loss_ins: 0.4754  loss_cate: 0.03573  time: 5.8029  data_time: 0.0206  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:23:19 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/model_final.pth\n",
      "\u001b[32m[05/18 08:23:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4499  total_loss: 0.4138  loss_ins: 0.3879  loss_cate: 0.03257  time: 5.8029  data_time: 0.0204  lr: 1e-05  max_mem: 9183M\n",
      "\u001b[32m[05/18 08:23:19 d2.engine.hooks]: \u001b[0mOverall training speed: 4497 iterations in 7:15:01 (5.8042 s / it)\n",
      "\u001b[32m[05/18 08:23:19 d2.engine.hooks]: \u001b[0mTotal training time: 7:15:30 (0:00:28 on hooks)\n",
      "\u001b[32m[05/18 08:23:20 d2.data.datasets.coco]: \u001b[0mLoaded 1889 images in COCO format from /home/outletters/trashcan/Augmented/val_annotation.json\n",
      "\u001b[32m[05/18 08:23:20 d2.data.build]: \u001b[0mDistribution of instances among all 22 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      rov      | 684          |     plant     | 200          |  animal_fish  | 305          |\n",
      "| animal_star.. | 254          | animal_shells | 163          |  animal_crab  | 163          |\n",
      "|  animal_eel   | 150          |  animal_etc   | 123          | trash_cloth.. | 37           |\n",
      "|  trash_pipe   | 86           | trash_bottle  | 64           |   trash_bag   | 181          |\n",
      "| trash_snack.. | 37           |   trash_can   | 151          |   trash_cup   | 16           |\n",
      "| trash_conta.. | 301          | trash_unkno.. | 553          | trash_branch  | 172          |\n",
      "| trash_wreck.. | 97           |  trash_tarp   | 67           |  trash_rope   | 43           |\n",
      "|   trash_net   | 45           |               |              |               |              |\n",
      "|     total     | 3892         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[05/18 08:23:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/18 08:23:20 d2.data.common]: \u001b[0mSerializing 1889 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/18 08:23:20 d2.data.common]: \u001b[0mSerialized dataset takes 2.68 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/18 08:23:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[05/18 08:23:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 1889 images\n",
      "\u001b[32m[05/18 08:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/1889. 0.7657 s / img. ETA=0:25:02\n",
      "\u001b[32m[05/18 08:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 18/1889. 0.7555 s / img. ETA=0:24:36\n",
      "\u001b[32m[05/18 08:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 25/1889. 0.7894 s / img. ETA=0:25:32\n",
      "\u001b[32m[05/18 08:23:47 d2.evaluation.evaluator]: \u001b[0mInference done 32/1889. 0.7913 s / img. ETA=0:25:29\n",
      "\u001b[32m[05/18 08:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 38/1889. 0.8081 s / img. ETA=0:25:55\n",
      "\u001b[32m[05/18 08:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 43/1889. 0.8362 s / img. ETA=0:26:41\n",
      "\u001b[32m[05/18 08:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 50/1889. 0.8202 s / img. ETA=0:26:06\n",
      "\u001b[32m[05/18 08:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 57/1889. 0.8161 s / img. ETA=0:25:52\n",
      "\u001b[32m[05/18 08:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 64/1889. 0.8052 s / img. ETA=0:25:27\n",
      "\u001b[32m[05/18 08:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 70/1889. 0.8067 s / img. ETA=0:25:24\n",
      "\u001b[32m[05/18 08:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 75/1889. 0.8208 s / img. ETA=0:25:45\n",
      "\u001b[32m[05/18 08:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 81/1889. 0.8206 s / img. ETA=0:25:39\n",
      "\u001b[32m[05/18 08:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 87/1889. 0.8201 s / img. ETA=0:25:34\n",
      "\u001b[32m[05/18 08:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 93/1889. 0.8217 s / img. ETA=0:25:31\n",
      "\u001b[32m[05/18 08:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 100/1889. 0.8138 s / img. ETA=0:25:11\n",
      "\u001b[32m[05/18 08:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 107/1889. 0.8119 s / img. ETA=0:25:02\n",
      "\u001b[32m[05/18 08:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 114/1889. 0.8100 s / img. ETA=0:24:52\n",
      "\u001b[32m[05/18 08:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 121/1889. 0.8053 s / img. ETA=0:24:38\n",
      "\u001b[32m[05/18 08:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 127/1889. 0.8077 s / img. ETA=0:24:37\n",
      "\u001b[32m[05/18 08:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 133/1889. 0.8083 s / img. ETA=0:24:33\n",
      "\u001b[32m[05/18 08:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 140/1889. 0.8045 s / img. ETA=0:24:21\n",
      "\u001b[32m[05/18 08:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 148/1889. 0.7962 s / img. ETA=0:24:00\n",
      "\u001b[32m[05/18 08:25:28 d2.evaluation.evaluator]: \u001b[0mInference done 155/1889. 0.7944 s / img. ETA=0:23:51\n",
      "\u001b[32m[05/18 08:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 162/1889. 0.7935 s / img. ETA=0:23:44\n",
      "\u001b[32m[05/18 08:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 170/1889. 0.7881 s / img. ETA=0:23:28\n",
      "\u001b[32m[05/18 08:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 177/1889. 0.7859 s / img. ETA=0:23:19\n",
      "\u001b[32m[05/18 08:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 184/1889. 0.7851 s / img. ETA=0:23:12\n",
      "\u001b[32m[05/18 08:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 191/1889. 0.7854 s / img. ETA=0:23:07\n",
      "\u001b[32m[05/18 08:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 198/1889. 0.7847 s / img. ETA=0:23:00\n",
      "\u001b[32m[05/18 08:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 205/1889. 0.7826 s / img. ETA=0:22:51\n",
      "\u001b[32m[05/18 08:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 212/1889. 0.7814 s / img. ETA=0:22:43\n",
      "\u001b[32m[05/18 08:26:19 d2.evaluation.evaluator]: \u001b[0mInference done 219/1889. 0.7813 s / img. ETA=0:22:37\n",
      "\u001b[32m[05/18 08:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 225/1889. 0.7820 s / img. ETA=0:22:33\n",
      "\u001b[32m[05/18 08:26:29 d2.evaluation.evaluator]: \u001b[0mInference done 232/1889. 0.7811 s / img. ETA=0:22:26\n",
      "\u001b[32m[05/18 08:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 239/1889. 0.7814 s / img. ETA=0:22:21\n",
      "\u001b[32m[05/18 08:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 245/1889. 0.7820 s / img. ETA=0:22:17\n",
      "\u001b[32m[05/18 08:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 252/1889. 0.7819 s / img. ETA=0:22:11\n",
      "\u001b[32m[05/18 08:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 258/1889. 0.7842 s / img. ETA=0:22:10\n",
      "\u001b[32m[05/18 08:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 265/1889. 0.7810 s / img. ETA=0:22:00\n",
      "\u001b[32m[05/18 08:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 272/1889. 0.7796 s / img. ETA=0:21:52\n",
      "\u001b[32m[05/18 08:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 278/1889. 0.7804 s / img. ETA=0:21:49\n",
      "\u001b[32m[05/18 08:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 285/1889. 0.7807 s / img. ETA=0:21:44\n",
      "\u001b[32m[05/18 08:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 292/1889. 0.7804 s / img. ETA=0:21:37\n",
      "\u001b[32m[05/18 08:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 299/1889. 0.7789 s / img. ETA=0:21:29\n",
      "\u001b[32m[05/18 08:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 305/1889. 0.7797 s / img. ETA=0:21:26\n",
      "\u001b[32m[05/18 08:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 312/1889. 0.7784 s / img. ETA=0:21:18\n",
      "\u001b[32m[05/18 08:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 319/1889. 0.7770 s / img. ETA=0:21:10\n",
      "\u001b[32m[05/18 08:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 326/1889. 0.7768 s / img. ETA=0:21:04\n",
      "\u001b[32m[05/18 08:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 333/1889. 0.7760 s / img. ETA=0:20:57\n",
      "\u001b[32m[05/18 08:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 340/1889. 0.7760 s / img. ETA=0:20:52\n",
      "\u001b[32m[05/18 08:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 347/1889. 0.7755 s / img. ETA=0:20:45\n",
      "\u001b[32m[05/18 08:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 354/1889. 0.7740 s / img. ETA=0:20:37\n",
      "\u001b[32m[05/18 08:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 361/1889. 0.7742 s / img. ETA=0:20:32\n",
      "\u001b[32m[05/18 08:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 368/1889. 0.7739 s / img. ETA=0:20:26\n",
      "\u001b[32m[05/18 08:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 375/1889. 0.7742 s / img. ETA=0:20:20\n",
      "\u001b[32m[05/18 08:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 382/1889. 0.7743 s / img. ETA=0:20:15\n",
      "\u001b[32m[05/18 08:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 389/1889. 0.7738 s / img. ETA=0:20:08\n",
      "\u001b[32m[05/18 08:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 395/1889. 0.7742 s / img. ETA=0:20:04\n",
      "\u001b[32m[05/18 08:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 401/1889. 0.7749 s / img. ETA=0:20:00\n",
      "\u001b[32m[05/18 08:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 408/1889. 0.7741 s / img. ETA=0:19:54\n",
      "\u001b[32m[05/18 08:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 415/1889. 0.7741 s / img. ETA=0:19:48\n",
      "\u001b[32m[05/18 08:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 422/1889. 0.7740 s / img. ETA=0:19:42\n",
      "\u001b[32m[05/18 08:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 429/1889. 0.7741 s / img. ETA=0:19:37\n",
      "\u001b[32m[05/18 08:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 436/1889. 0.7730 s / img. ETA=0:19:29\n",
      "\u001b[32m[05/18 08:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 443/1889. 0.7730 s / img. ETA=0:19:24\n",
      "\u001b[32m[05/18 08:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 450/1889. 0.7726 s / img. ETA=0:19:17\n",
      "\u001b[32m[05/18 08:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 457/1889. 0.7730 s / img. ETA=0:19:12\n",
      "\u001b[32m[05/18 08:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 463/1889. 0.7738 s / img. ETA=0:19:09\n",
      "\u001b[32m[05/18 08:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 470/1889. 0.7740 s / img. ETA=0:19:03\n",
      "\u001b[32m[05/18 08:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 477/1889. 0.7735 s / img. ETA=0:18:57\n",
      "\u001b[32m[05/18 08:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 483/1889. 0.7740 s / img. ETA=0:18:53\n",
      "\u001b[32m[05/18 08:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 489/1889. 0.7746 s / img. ETA=0:18:49\n",
      "\u001b[32m[05/18 08:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 495/1889. 0.7753 s / img. ETA=0:18:45\n",
      "\u001b[32m[05/18 08:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 502/1889. 0.7743 s / img. ETA=0:18:38\n",
      "\u001b[32m[05/18 08:30:11 d2.evaluation.evaluator]: \u001b[0mInference done 509/1889. 0.7741 s / img. ETA=0:18:32\n",
      "\u001b[32m[05/18 08:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 516/1889. 0.7742 s / img. ETA=0:18:26\n",
      "\u001b[32m[05/18 08:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 523/1889. 0.7742 s / img. ETA=0:18:21\n",
      "\u001b[32m[05/18 08:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 530/1889. 0.7730 s / img. ETA=0:18:13\n",
      "\u001b[32m[05/18 08:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 538/1889. 0.7714 s / img. ETA=0:18:05\n",
      "\u001b[32m[05/18 08:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 545/1889. 0.7708 s / img. ETA=0:17:59\n",
      "\u001b[32m[05/18 08:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 551/1889. 0.7714 s / img. ETA=0:17:55\n",
      "\u001b[32m[05/18 08:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 557/1889. 0.7718 s / img. ETA=0:17:51\n",
      "\u001b[32m[05/18 08:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 564/1889. 0.7719 s / img. ETA=0:17:45\n",
      "\u001b[32m[05/18 08:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 571/1889. 0.7718 s / img. ETA=0:17:39\n",
      "\u001b[32m[05/18 08:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 578/1889. 0.7720 s / img. ETA=0:17:34\n",
      "\u001b[32m[05/18 08:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 584/1889. 0.7724 s / img. ETA=0:17:30\n",
      "\u001b[32m[05/18 08:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 591/1889. 0.7720 s / img. ETA=0:17:23\n",
      "\u001b[32m[05/18 08:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 598/1889. 0.7719 s / img. ETA=0:17:18\n",
      "\u001b[32m[05/18 08:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 605/1889. 0.7712 s / img. ETA=0:17:11\n",
      "\u001b[32m[05/18 08:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 611/1889. 0.7720 s / img. ETA=0:17:07\n",
      "\u001b[32m[05/18 08:31:38 d2.evaluation.evaluator]: \u001b[0mInference done 618/1889. 0.7721 s / img. ETA=0:17:02\n",
      "\u001b[32m[05/18 08:31:43 d2.evaluation.evaluator]: \u001b[0mInference done 624/1889. 0.7725 s / img. ETA=0:16:57\n",
      "\u001b[32m[05/18 08:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 631/1889. 0.7714 s / img. ETA=0:16:50\n",
      "\u001b[32m[05/18 08:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 638/1889. 0.7717 s / img. ETA=0:16:45\n",
      "\u001b[32m[05/18 08:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 645/1889. 0.7715 s / img. ETA=0:16:39\n",
      "\u001b[32m[05/18 08:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 652/1889. 0.7709 s / img. ETA=0:16:33\n",
      "\u001b[32m[05/18 08:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 658/1889. 0.7714 s / img. ETA=0:16:29\n",
      "\u001b[32m[05/18 08:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 664/1889. 0.7718 s / img. ETA=0:16:24\n",
      "\u001b[32m[05/18 08:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 671/1889. 0.7716 s / img. ETA=0:16:18\n",
      "\u001b[32m[05/18 08:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 678/1889. 0.7718 s / img. ETA=0:16:13\n",
      "\u001b[32m[05/18 08:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 684/1889. 0.7721 s / img. ETA=0:16:08\n",
      "\u001b[32m[05/18 08:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 690/1889. 0.7725 s / img. ETA=0:16:04\n",
      "\u001b[32m[05/18 08:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 696/1889. 0.7730 s / img. ETA=0:16:00\n",
      "\u001b[32m[05/18 08:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 703/1889. 0.7733 s / img. ETA=0:15:55\n",
      "\u001b[32m[05/18 08:32:52 d2.evaluation.evaluator]: \u001b[0mInference done 710/1889. 0.7733 s / img. ETA=0:15:49\n",
      "\u001b[32m[05/18 08:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 716/1889. 0.7738 s / img. ETA=0:15:45\n",
      "\u001b[32m[05/18 08:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 722/1889. 0.7743 s / img. ETA=0:15:40\n",
      "\u001b[32m[05/18 08:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 729/1889. 0.7735 s / img. ETA=0:15:34\n",
      "\u001b[32m[05/18 08:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 736/1889. 0.7733 s / img. ETA=0:15:28\n",
      "\u001b[32m[05/18 08:33:19 d2.evaluation.evaluator]: \u001b[0mInference done 743/1889. 0.7733 s / img. ETA=0:15:22\n",
      "\u001b[32m[05/18 08:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 750/1889. 0.7734 s / img. ETA=0:15:17\n",
      "\u001b[32m[05/18 08:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 757/1889. 0.7732 s / img. ETA=0:15:11\n",
      "\u001b[32m[05/18 08:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 764/1889. 0.7728 s / img. ETA=0:15:05\n",
      "\u001b[32m[05/18 08:33:41 d2.evaluation.evaluator]: \u001b[0mInference done 771/1889. 0.7727 s / img. ETA=0:14:59\n",
      "\u001b[32m[05/18 08:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 777/1889. 0.7738 s / img. ETA=0:14:55\n",
      "\u001b[32m[05/18 08:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 784/1889. 0.7736 s / img. ETA=0:14:50\n",
      "\u001b[32m[05/18 08:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 791/1889. 0.7735 s / img. ETA=0:14:44\n",
      "\u001b[32m[05/18 08:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 798/1889. 0.7732 s / img. ETA=0:14:38\n",
      "\u001b[32m[05/18 08:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 805/1889. 0.7734 s / img. ETA=0:14:32\n",
      "\u001b[32m[05/18 08:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 811/1889. 0.7739 s / img. ETA=0:14:28\n",
      "\u001b[32m[05/18 08:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 818/1889. 0.7739 s / img. ETA=0:14:22\n",
      "\u001b[32m[05/18 08:34:25 d2.evaluation.evaluator]: \u001b[0mInference done 825/1889. 0.7737 s / img. ETA=0:14:17\n",
      "\u001b[32m[05/18 08:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 831/1889. 0.7739 s / img. ETA=0:14:12\n",
      "\u001b[32m[05/18 08:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 837/1889. 0.7749 s / img. ETA=0:14:08\n",
      "\u001b[32m[05/18 08:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 844/1889. 0.7748 s / img. ETA=0:14:02\n",
      "\u001b[32m[05/18 08:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 851/1889. 0.7745 s / img. ETA=0:13:57\n",
      "\u001b[32m[05/18 08:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 858/1889. 0.7745 s / img. ETA=0:13:51\n",
      "\u001b[32m[05/18 08:34:58 d2.evaluation.evaluator]: \u001b[0mInference done 866/1889. 0.7735 s / img. ETA=0:13:43\n",
      "\u001b[32m[05/18 08:35:03 d2.evaluation.evaluator]: \u001b[0mInference done 872/1889. 0.7740 s / img. ETA=0:13:39\n",
      "\u001b[32m[05/18 08:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 879/1889. 0.7741 s / img. ETA=0:13:34\n",
      "\u001b[32m[05/18 08:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 886/1889. 0.7735 s / img. ETA=0:13:27\n",
      "\u001b[32m[05/18 08:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 892/1889. 0.7738 s / img. ETA=0:13:23\n",
      "\u001b[32m[05/18 08:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 899/1889. 0.7737 s / img. ETA=0:13:17\n",
      "\u001b[32m[05/18 08:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 906/1889. 0.7736 s / img. ETA=0:13:11\n",
      "\u001b[32m[05/18 08:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 913/1889. 0.7733 s / img. ETA=0:13:05\n",
      "\u001b[32m[05/18 08:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 920/1889. 0.7735 s / img. ETA=0:13:00\n",
      "\u001b[32m[05/18 08:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 927/1889. 0.7733 s / img. ETA=0:12:54\n",
      "\u001b[32m[05/18 08:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 933/1889. 0.7736 s / img. ETA=0:12:50\n",
      "\u001b[32m[05/18 08:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 939/1889. 0.7740 s / img. ETA=0:12:45\n",
      "\u001b[32m[05/18 08:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 945/1889. 0.7742 s / img. ETA=0:12:40\n",
      "\u001b[32m[05/18 08:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 952/1889. 0.7739 s / img. ETA=0:12:34\n",
      "\u001b[32m[05/18 08:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 959/1889. 0.7734 s / img. ETA=0:12:28\n",
      "\u001b[32m[05/18 08:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 965/1889. 0.7736 s / img. ETA=0:12:24\n",
      "\u001b[32m[05/18 08:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 972/1889. 0.7734 s / img. ETA=0:12:18\n",
      "\u001b[32m[05/18 08:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 979/1889. 0.7736 s / img. ETA=0:12:12\n",
      "\u001b[32m[05/18 08:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 986/1889. 0.7737 s / img. ETA=0:12:07\n",
      "\u001b[32m[05/18 08:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 993/1889. 0.7738 s / img. ETA=0:12:01\n",
      "\u001b[32m[05/18 08:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 999/1889. 0.7740 s / img. ETA=0:11:57\n",
      "\u001b[32m[05/18 08:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 1006/1889. 0.7736 s / img. ETA=0:11:51\n",
      "\u001b[32m[05/18 08:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 1013/1889. 0.7732 s / img. ETA=0:11:45\n",
      "\u001b[32m[05/18 08:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 1020/1889. 0.7732 s / img. ETA=0:11:39\n",
      "\u001b[32m[05/18 08:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 1026/1889. 0.7735 s / img. ETA=0:11:35\n",
      "\u001b[32m[05/18 08:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 1033/1889. 0.7736 s / img. ETA=0:11:29\n",
      "\u001b[32m[05/18 08:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 1040/1889. 0.7738 s / img. ETA=0:11:23\n",
      "\u001b[32m[05/18 08:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 1047/1889. 0.7735 s / img. ETA=0:11:18\n",
      "\u001b[32m[05/18 08:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 1054/1889. 0.7735 s / img. ETA=0:11:12\n",
      "\u001b[32m[05/18 08:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 1061/1889. 0.7735 s / img. ETA=0:11:06\n",
      "\u001b[32m[05/18 08:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 1068/1889. 0.7732 s / img. ETA=0:11:00\n",
      "\u001b[32m[05/18 08:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 1075/1889. 0.7730 s / img. ETA=0:10:55\n",
      "\u001b[32m[05/18 08:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 1082/1889. 0.7730 s / img. ETA=0:10:49\n",
      "\u001b[32m[05/18 08:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 1089/1889. 0.7727 s / img. ETA=0:10:43\n",
      "\u001b[32m[05/18 08:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 1096/1889. 0.7727 s / img. ETA=0:10:37\n",
      "\u001b[32m[05/18 08:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 1102/1889. 0.7730 s / img. ETA=0:10:33\n",
      "\u001b[32m[05/18 08:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 1108/1889. 0.7733 s / img. ETA=0:10:28\n",
      "\u001b[32m[05/18 08:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 1114/1889. 0.7736 s / img. ETA=0:10:24\n",
      "\u001b[32m[05/18 08:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 1120/1889. 0.7740 s / img. ETA=0:10:19\n",
      "\u001b[32m[05/18 08:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 1127/1889. 0.7739 s / img. ETA=0:10:13\n",
      "\u001b[32m[05/18 08:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 1133/1889. 0.7741 s / img. ETA=0:10:09\n",
      "\u001b[32m[05/18 08:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 1140/1889. 0.7738 s / img. ETA=0:10:03\n",
      "\u001b[32m[05/18 08:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 1147/1889. 0.7738 s / img. ETA=0:09:57\n",
      "\u001b[32m[05/18 08:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 1154/1889. 0.7739 s / img. ETA=0:09:52\n",
      "\u001b[32m[05/18 08:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 1161/1889. 0.7734 s / img. ETA=0:09:46\n",
      "\u001b[32m[05/18 08:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 1168/1889. 0.7734 s / img. ETA=0:09:40\n",
      "\u001b[32m[05/18 08:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 1175/1889. 0.7736 s / img. ETA=0:09:34\n",
      "\u001b[32m[05/18 08:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 1182/1889. 0.7737 s / img. ETA=0:09:29\n",
      "\u001b[32m[05/18 08:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 1188/1889. 0.7739 s / img. ETA=0:09:24\n",
      "\u001b[32m[05/18 08:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 1194/1889. 0.7741 s / img. ETA=0:09:20\n",
      "\u001b[32m[05/18 08:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 1201/1889. 0.7739 s / img. ETA=0:09:14\n",
      "\u001b[32m[05/18 08:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 1208/1889. 0.7736 s / img. ETA=0:09:08\n",
      "\u001b[32m[05/18 08:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 1214/1889. 0.7738 s / img. ETA=0:09:03\n",
      "\u001b[32m[05/18 08:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 1220/1889. 0.7741 s / img. ETA=0:08:59\n",
      "\u001b[32m[05/18 08:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 1226/1889. 0.7743 s / img. ETA=0:08:54\n",
      "\u001b[32m[05/18 08:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 1233/1889. 0.7743 s / img. ETA=0:08:48\n",
      "\u001b[32m[05/18 08:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 1240/1889. 0.7741 s / img. ETA=0:08:42\n",
      "\u001b[32m[05/18 08:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 1247/1889. 0.7739 s / img. ETA=0:08:37\n",
      "\u001b[32m[05/18 08:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 1254/1889. 0.7735 s / img. ETA=0:08:31\n",
      "\u001b[32m[05/18 08:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 1261/1889. 0.7735 s / img. ETA=0:08:25\n",
      "\u001b[32m[05/18 08:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 1267/1889. 0.7737 s / img. ETA=0:08:20\n",
      "\u001b[32m[05/18 08:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 1274/1889. 0.7738 s / img. ETA=0:08:15\n",
      "\u001b[32m[05/18 08:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 1280/1889. 0.7742 s / img. ETA=0:08:10\n",
      "\u001b[32m[05/18 08:40:37 d2.evaluation.evaluator]: \u001b[0mInference done 1286/1889. 0.7745 s / img. ETA=0:08:06\n",
      "\u001b[32m[05/18 08:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 1293/1889. 0.7744 s / img. ETA=0:08:00\n",
      "\u001b[32m[05/18 08:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 1300/1889. 0.7741 s / img. ETA=0:07:54\n",
      "\u001b[32m[05/18 08:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 1307/1889. 0.7742 s / img. ETA=0:07:49\n",
      "\u001b[32m[05/18 08:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 1314/1889. 0.7737 s / img. ETA=0:07:43\n",
      "\u001b[32m[05/18 08:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 1321/1889. 0.7735 s / img. ETA=0:07:37\n",
      "\u001b[32m[05/18 08:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 1328/1889. 0.7736 s / img. ETA=0:07:31\n",
      "\u001b[32m[05/18 08:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 1335/1889. 0.7733 s / img. ETA=0:07:25\n",
      "\u001b[32m[05/18 08:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 1341/1889. 0.7735 s / img. ETA=0:07:21\n",
      "\u001b[32m[05/18 08:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 1348/1889. 0.7733 s / img. ETA=0:07:15\n",
      "\u001b[32m[05/18 08:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 1354/1889. 0.7735 s / img. ETA=0:07:10\n",
      "\u001b[32m[05/18 08:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 1361/1889. 0.7735 s / img. ETA=0:07:05\n",
      "\u001b[32m[05/18 08:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 1368/1889. 0.7736 s / img. ETA=0:06:59\n",
      "\u001b[32m[05/18 08:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 1375/1889. 0.7733 s / img. ETA=0:06:53\n",
      "\u001b[32m[05/18 08:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 1382/1889. 0.7732 s / img. ETA=0:06:48\n",
      "\u001b[32m[05/18 08:41:59 d2.evaluation.evaluator]: \u001b[0mInference done 1389/1889. 0.7730 s / img. ETA=0:06:42\n",
      "\u001b[32m[05/18 08:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 1395/1889. 0.7732 s / img. ETA=0:06:37\n",
      "\u001b[32m[05/18 08:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 1402/1889. 0.7732 s / img. ETA=0:06:32\n",
      "\u001b[32m[05/18 08:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 1408/1889. 0.7735 s / img. ETA=0:06:27\n",
      "\u001b[32m[05/18 08:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 1415/1889. 0.7736 s / img. ETA=0:06:21\n",
      "\u001b[32m[05/18 08:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 1422/1889. 0.7736 s / img. ETA=0:06:16\n",
      "\u001b[32m[05/18 08:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 1428/1889. 0.7738 s / img. ETA=0:06:11\n",
      "\u001b[32m[05/18 08:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 1435/1889. 0.7739 s / img. ETA=0:06:05\n",
      "\u001b[32m[05/18 08:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 1442/1889. 0.7736 s / img. ETA=0:06:00\n",
      "\u001b[32m[05/18 08:42:47 d2.evaluation.evaluator]: \u001b[0mInference done 1449/1889. 0.7733 s / img. ETA=0:05:54\n",
      "\u001b[32m[05/18 08:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 1455/1889. 0.7736 s / img. ETA=0:05:49\n",
      "\u001b[32m[05/18 08:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 1461/1889. 0.7739 s / img. ETA=0:05:44\n",
      "\u001b[32m[05/18 08:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 1468/1889. 0.7737 s / img. ETA=0:05:39\n",
      "\u001b[32m[05/18 08:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 1474/1889. 0.7740 s / img. ETA=0:05:34\n",
      "\u001b[32m[05/18 08:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 1480/1889. 0.7741 s / img. ETA=0:05:29\n",
      "\u001b[32m[05/18 08:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 1487/1889. 0.7742 s / img. ETA=0:05:24\n",
      "\u001b[32m[05/18 08:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 1494/1889. 0.7740 s / img. ETA=0:05:18\n",
      "\u001b[32m[05/18 08:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 1501/1889. 0.7739 s / img. ETA=0:05:12\n",
      "\u001b[32m[05/18 08:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 1508/1889. 0.7735 s / img. ETA=0:05:06\n",
      "\u001b[32m[05/18 08:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 1515/1889. 0.7734 s / img. ETA=0:05:01\n",
      "\u001b[32m[05/18 08:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 1520/1889. 0.7741 s / img. ETA=0:04:57\n",
      "\u001b[32m[05/18 08:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 1528/1889. 0.7737 s / img. ETA=0:04:50\n",
      "\u001b[32m[05/18 08:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 1535/1889. 0.7736 s / img. ETA=0:04:45\n",
      "\u001b[32m[05/18 08:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 1541/1889. 0.7739 s / img. ETA=0:04:40\n",
      "\u001b[32m[05/18 08:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 1548/1889. 0.7739 s / img. ETA=0:04:34\n",
      "\u001b[32m[05/18 08:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 1555/1889. 0.7737 s / img. ETA=0:04:29\n",
      "\u001b[32m[05/18 08:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 1561/1889. 0.7740 s / img. ETA=0:04:24\n",
      "\u001b[32m[05/18 08:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 1567/1889. 0.7742 s / img. ETA=0:04:19\n",
      "\u001b[32m[05/18 08:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 1574/1889. 0.7739 s / img. ETA=0:04:13\n",
      "\u001b[32m[05/18 08:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 1581/1889. 0.7740 s / img. ETA=0:04:08\n",
      "\u001b[32m[05/18 08:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 1588/1889. 0.7741 s / img. ETA=0:04:02\n",
      "\u001b[32m[05/18 08:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 1594/1889. 0.7742 s / img. ETA=0:03:57\n",
      "\u001b[32m[05/18 08:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 1601/1889. 0.7738 s / img. ETA=0:03:52\n",
      "\u001b[32m[05/18 08:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 1608/1889. 0.7737 s / img. ETA=0:03:46\n",
      "\u001b[32m[05/18 08:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 1614/1889. 0.7739 s / img. ETA=0:03:41\n",
      "\u001b[32m[05/18 08:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 1620/1889. 0.7741 s / img. ETA=0:03:36\n",
      "\u001b[32m[05/18 08:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 1627/1889. 0.7742 s / img. ETA=0:03:31\n",
      "\u001b[32m[05/18 08:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 1634/1889. 0.7741 s / img. ETA=0:03:25\n",
      "\u001b[32m[05/18 08:45:23 d2.evaluation.evaluator]: \u001b[0mInference done 1641/1889. 0.7740 s / img. ETA=0:03:19\n",
      "\u001b[32m[05/18 08:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 1648/1889. 0.7739 s / img. ETA=0:03:14\n",
      "\u001b[32m[05/18 08:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 1655/1889. 0.7739 s / img. ETA=0:03:08\n",
      "\u001b[32m[05/18 08:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 1662/1889. 0.7737 s / img. ETA=0:03:02\n",
      "\u001b[32m[05/18 08:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 1668/1889. 0.7738 s / img. ETA=0:02:58\n",
      "\u001b[32m[05/18 08:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 1675/1889. 0.7736 s / img. ETA=0:02:52\n",
      "\u001b[32m[05/18 08:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 1682/1889. 0.7736 s / img. ETA=0:02:46\n",
      "\u001b[32m[05/18 08:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 1689/1889. 0.7734 s / img. ETA=0:02:41\n",
      "\u001b[32m[05/18 08:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 1696/1889. 0.7731 s / img. ETA=0:02:35\n",
      "\u001b[32m[05/18 08:46:12 d2.evaluation.evaluator]: \u001b[0mInference done 1703/1889. 0.7732 s / img. ETA=0:02:29\n",
      "\u001b[32m[05/18 08:46:17 d2.evaluation.evaluator]: \u001b[0mInference done 1710/1889. 0.7729 s / img. ETA=0:02:24\n",
      "\u001b[32m[05/18 08:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 1718/1889. 0.7725 s / img. ETA=0:02:17\n",
      "\u001b[32m[05/18 08:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 1724/1889. 0.7726 s / img. ETA=0:02:12\n",
      "\u001b[32m[05/18 08:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 1731/1889. 0.7725 s / img. ETA=0:02:07\n",
      "\u001b[32m[05/18 08:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 1738/1889. 0.7724 s / img. ETA=0:02:01\n",
      "\u001b[32m[05/18 08:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 1744/1889. 0.7725 s / img. ETA=0:01:56\n",
      "\u001b[32m[05/18 08:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 1751/1889. 0.7725 s / img. ETA=0:01:51\n",
      "\u001b[32m[05/18 08:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 1758/1889. 0.7722 s / img. ETA=0:01:45\n",
      "\u001b[32m[05/18 08:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 1764/1889. 0.7724 s / img. ETA=0:01:40\n",
      "\u001b[32m[05/18 08:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 1771/1889. 0.7725 s / img. ETA=0:01:34\n",
      "\u001b[32m[05/18 08:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 1778/1889. 0.7724 s / img. ETA=0:01:29\n",
      "\u001b[32m[05/18 08:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 1785/1889. 0.7724 s / img. ETA=0:01:23\n",
      "\u001b[32m[05/18 08:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 1792/1889. 0.7724 s / img. ETA=0:01:18\n",
      "\u001b[32m[05/18 08:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 1798/1889. 0.7726 s / img. ETA=0:01:13\n",
      "\u001b[32m[05/18 08:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 1805/1889. 0.7725 s / img. ETA=0:01:07\n",
      "\u001b[32m[05/18 08:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 1812/1889. 0.7724 s / img. ETA=0:01:01\n",
      "\u001b[32m[05/18 08:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 1819/1889. 0.7723 s / img. ETA=0:00:56\n",
      "\u001b[32m[05/18 08:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 1825/1889. 0.7724 s / img. ETA=0:00:51\n",
      "\u001b[32m[05/18 08:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 1831/1889. 0.7726 s / img. ETA=0:00:46\n",
      "\u001b[32m[05/18 08:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 1838/1889. 0.7724 s / img. ETA=0:00:41\n",
      "\u001b[32m[05/18 08:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 1845/1889. 0.7723 s / img. ETA=0:00:35\n",
      "\u001b[32m[05/18 08:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 1852/1889. 0.7723 s / img. ETA=0:00:29\n",
      "\u001b[32m[05/18 08:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 1859/1889. 0.7722 s / img. ETA=0:00:24\n",
      "\u001b[32m[05/18 08:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 1866/1889. 0.7722 s / img. ETA=0:00:18\n",
      "\u001b[32m[05/18 08:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 1872/1889. 0.7725 s / img. ETA=0:00:13\n",
      "\u001b[32m[05/18 08:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 1879/1889. 0.7725 s / img. ETA=0:00:08\n",
      "\u001b[32m[05/18 08:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 1886/1889. 0.7726 s / img. ETA=0:00:02\n",
      "\u001b[32m[05/18 08:48:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:25:15.587856 (0.804452 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/18 08:48:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:24:15 (0.772543 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/18 08:48:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/18 08:48:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x/inference/coco_instances_results.json\n",
      "\u001b[32m[05/18 08:48:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/18 08:48:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[05/18 08:48:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 3.07 seconds.\n",
      "\u001b[32m[05/18 08:48:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/18 08:48:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.65 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[05/18 08:48:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[05/18 08:48:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category            | AP    | category               | AP    | category       | AP    |\n",
      "|:--------------------|:------|:-----------------------|:------|:---------------|:------|\n",
      "| rov                 | 0.000 | plant                  | 0.000 | animal_fish    | 0.000 |\n",
      "| animal_starfish     | 0.000 | animal_shells          | 0.000 | animal_crab    | 0.000 |\n",
      "| animal_eel          | 0.000 | animal_etc             | 0.000 | trash_clothing | 0.000 |\n",
      "| trash_pipe          | 0.000 | trash_bottle           | 0.000 | trash_bag      | 0.000 |\n",
      "| trash_snack_wrapper | 0.000 | trash_can              | 0.000 | trash_cup      | 0.000 |\n",
      "| trash_container     | 0.000 | trash_unknown_instance | 0.000 | trash_branch   | 0.000 |\n",
      "| trash_wreckage      | 0.000 | trash_tarp             | 0.000 | trash_rope     | 0.000 |\n",
      "| trash_net           | 0.000 |                        |       |                |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=4.24s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/18 08:48:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[05/18 08:49:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 4.85 seconds.\n",
      "\u001b[32m[05/18 08:49:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.66 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.004 | 31.304 | 11.865 | 5.436 | 20.125 | 35.068 |\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category            | AP     | category               | AP     | category       | AP     |\n",
      "|:--------------------|:-------|:-----------------------|:-------|:---------------|:-------|\n",
      "| rov                 | 38.970 | plant                  | 8.318  | animal_fish    | 2.804  |\n",
      "| animal_starfish     | 0.293  | animal_shells          | 4.687  | animal_crab    | 3.885  |\n",
      "| animal_eel          | 7.534  | animal_etc             | 5.949  | trash_clothing | 6.779  |\n",
      "| trash_pipe          | 25.361 | trash_bottle           | 32.475 | trash_bag      | 16.214 |\n",
      "| trash_snack_wrapper | 2.442  | trash_can              | 29.858 | trash_cup      | 13.917 |\n",
      "| trash_container     | 39.502 | trash_unknown_instance | 7.856  | trash_branch   | 25.377 |\n",
      "| trash_wreckage      | 29.830 | trash_tarp             | 18.150 | trash_rope     | 9.500  |\n",
      "| trash_net           | 0.384  |                        |        |                |        |\n",
      "\u001b[32m[05/18 08:49:03 d2.engine.defaults]: \u001b[0mEvaluation results for trashcan_instance_val in csv format:\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[05/18 08:49:03 d2.evaluation.testing]: \u001b[0mcopypaste: 15.0039,31.3037,11.8645,5.4361,20.1247,35.0676\n",
      "\u001b[32m[05/18 08:49:03 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4499  total_loss: 0.4138  loss_ins: 0.3879  loss_cate: 0.03257  time: 5.8029  data_time: 0.0204  lr: 1e-05  max_mem: 9183M\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "args = argparse.Namespace(config_file='configs/SOLOv2/R50_1x.yaml',\n",
    "                          dist_url='tcp://127.0.0.1:49153',\n",
    "                          eval_only=False,\n",
    "                          machine_rank=0,\n",
    "                          num_gpus=1,\n",
    "                          num_machines=1,\n",
    "                          opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir_ins/SOLOv2_R50_1x'], resume=True)\n",
    "print(\"Command Line Args:\", args)\n",
    "launch(\n",
    "        main,\n",
    "        args.num_gpus,\n",
    "        num_machines=args.num_machines,\n",
    "        machine_rank=args.machine_rank,\n",
    "        dist_url=args.dist_url,\n",
    "        args=(args,),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8540f5ec-76aa-427a-8f92-7d54cac8763b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Args: Namespace(config_file='configs/SOLOv2/R50_1x.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/', 'MODEL.WEIGHTS', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth'], resume=False)\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ----------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]\n",
      "numpy                   1.19.4\n",
      "detectron2              0.4 @/home/outletters/.local/lib/python3.6/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 11.0\n",
      "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.7.1+cu110 @/home/outletters/.local/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   NVIDIA Tesla K80 (arch=3.7)\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  8.2.0\n",
      "torchvision             0.8.2+cu110 @/home/outletters/.local/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0\n",
      "fvcore                  0.1.3.post20210317\n",
      "cv2                     4.5.1\n",
      "----------------------  ----------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ----------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]\n",
      "numpy                   1.19.4\n",
      "detectron2              0.4 @/home/outletters/.local/lib/python3.6/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 11.0\n",
      "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.7.1+cu110 @/home/outletters/.local/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   NVIDIA Tesla K80 (arch=3.7)\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  8.2.0\n",
      "torchvision             0.8.2+cu110 @/home/outletters/.local/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0\n",
      "fvcore                  0.1.3.post20210317\n",
      "cv2                     4.5.1\n",
      "----------------------  ----------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80\n",
      "  - CuDNN 8.0.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/SOLOv2/R50_1x.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/', 'MODEL.WEIGHTS', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth'], resume=False)\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/SOLOv2/R50_1x.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/', 'MODEL.WEIGHTS', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth'], resume=False)\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mContents of args.config_file=configs/SOLOv2/R50_1x.yaml:\n",
      "_BASE_: \"Base-SOLOv2.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (3000, 4000)\n",
      "  MAX_ITER: 4500\n",
      "\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mContents of args.config_file=configs/SOLOv2/R50_1x.yaml:\n",
      "_BASE_: \"Base-SOLOv2.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (3000, 4000)\n",
      "  MAX_ITER: 4500\n",
      "\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('trashcan_instance_val',)\n",
      "  TRAIN: ('trashcan_instance_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    CROP_INSTANCE: True\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  HFLIP_TRAIN: True\n",
      "  MASK_FORMAT: bitmask\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 64, 128, 256, 512]]\n",
      "  BACKBONE:\n",
      "    ANTI_ALIAS: False\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  BASIS_MODULE:\n",
      "    ANN_SET: coco\n",
      "    COMMON_STRIDE: 8\n",
      "    CONVS_DIM: 128\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5']\n",
      "    LOSS_ON: False\n",
      "    LOSS_WEIGHT: 0.3\n",
      "    NAME: ProtoNet\n",
      "    NORM: SyncBN\n",
      "    NUM_BASES: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 3\n",
      "  BATEXT:\n",
      "    CANONICAL_SIZE: 96\n",
      "    CONV_DIM: 256\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4']\n",
      "    NUM_CHARS: 25\n",
      "    NUM_CONV: 2\n",
      "    POOLER_RESOLUTION: (8, 32)\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625)\n",
      "    RECOGNITION_LOSS: ctc\n",
      "    RECOGNIZER: attn\n",
      "    SAMPLING_RATIO: 1\n",
      "    VOC_SIZE: 96\n",
      "  BLENDMASK:\n",
      "    ATTN_SIZE: 14\n",
      "    BOTTOM_RESOLUTION: 56\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "    POOLER_SAMPLING_RATIO: 1\n",
      "    POOLER_SCALES: (0.25,)\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    TOP_INTERP: bilinear\n",
      "    VISUALIZE: False\n",
      "  BOXINST:\n",
      "    BOTTOM_PIXELS_REMOVED: 10\n",
      "    ENABLED: False\n",
      "    PAIRWISE:\n",
      "      COLOR_THRESH: 0.3\n",
      "      DILATION: 2\n",
      "      SIZE: 3\n",
      "      WARMUP_ITERS: 10000\n",
      "  BiFPN:\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    NUM_REPEATS: 6\n",
      "    OUT_CHANNELS: 160\n",
      "  CONDINST:\n",
      "    BOTTOM_PIXELS_REMOVED: -1\n",
      "    MASK_BRANCH:\n",
      "      CHANNELS: 128\n",
      "      IN_FEATURES: ['p3', 'p4', 'p5']\n",
      "      NORM: BN\n",
      "      NUM_CONVS: 4\n",
      "      OUT_CHANNELS: 8\n",
      "      SEMANTIC_LOSS_ON: False\n",
      "    MASK_HEAD:\n",
      "      CHANNELS: 8\n",
      "      DISABLE_REL_COORDS: False\n",
      "      NUM_LAYERS: 3\n",
      "      USE_FP16: False\n",
      "    MASK_OUT_STRIDE: 4\n",
      "    MAX_PROPOSALS: -1\n",
      "    TOPK_PROPOSALS_PER_IM: -1\n",
      "  DEVICE: cuda\n",
      "  DLA:\n",
      "    CONV_BODY: DLA34\n",
      "    NORM: FrozenBN\n",
      "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
      "  FCOS:\n",
      "    BOX_QUALITY: ctrness\n",
      "    CENTER_SAMPLE: True\n",
      "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
      "    INFERENCE_TH_TEST: 0.05\n",
      "    INFERENCE_TH_TRAIN: 0.05\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    LOC_LOSS_TYPE: giou\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    LOSS_NORMALIZER_CLS: fg\n",
      "    LOSS_WEIGHT_CLS: 1.0\n",
      "    NMS_TH: 0.6\n",
      "    NORM: GN\n",
      "    NUM_BOX_CONVS: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CLS_CONVS: 4\n",
      "    NUM_SHARE_CONVS: 0\n",
      "    POST_NMS_TOPK_TEST: 100\n",
      "    POST_NMS_TOPK_TRAIN: 100\n",
      "    POS_RADIUS: 1.5\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
      "    THRESH_WITH_CTR: False\n",
      "    TOP_LEVELS: 2\n",
      "    USE_DEFORMABLE: False\n",
      "    USE_RELU: True\n",
      "    USE_SCALE: True\n",
      "    YIELD_PROPOSAL: False\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  MEInst:\n",
      "    AGNOSTIC: True\n",
      "    CENTER_SAMPLE: True\n",
      "    DIM_MASK: 60\n",
      "    FLAG_PARAMETERS: False\n",
      "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
      "    GCN_KERNEL_SIZE: 9\n",
      "    INFERENCE_TH_TEST: 0.05\n",
      "    INFERENCE_TH_TRAIN: 0.05\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    LAST_DEFORMABLE: False\n",
      "    LOC_LOSS_TYPE: giou\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    LOSS_ON_MASK: False\n",
      "    MASK_LOSS_TYPE: mse\n",
      "    MASK_ON: True\n",
      "    MASK_SIZE: 28\n",
      "    NMS_TH: 0.6\n",
      "    NORM: GN\n",
      "    NUM_BOX_CONVS: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CLS_CONVS: 4\n",
      "    NUM_MASK_CONVS: 4\n",
      "    NUM_SHARE_CONVS: 0\n",
      "    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz\n",
      "    POST_NMS_TOPK_TEST: 100\n",
      "    POST_NMS_TOPK_TRAIN: 100\n",
      "    POS_RADIUS: 1.5\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SIGMOID: True\n",
      "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
      "    THRESH_WITH_CTR: False\n",
      "    TOP_LEVELS: 2\n",
      "    TYPE_DEFORMABLE: DCNv1\n",
      "    USE_DEFORMABLE: False\n",
      "    USE_GCN_IN_MASK: False\n",
      "    USE_RELU: True\n",
      "    USE_SCALE: True\n",
      "    WHITEN: True\n",
      "  META_ARCHITECTURE: SOLOv2\n",
      "  MOBILENET: False\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_INTERVAL: 1\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  SOLOV2:\n",
      "    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]\n",
      "    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))\n",
      "    INSTANCE_CHANNELS: 512\n",
      "    INSTANCE_IN_CHANNELS: 256\n",
      "    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    LOSS:\n",
      "      DICE_WEIGHT: 3.0\n",
      "      FOCAL_ALPHA: 0.25\n",
      "      FOCAL_GAMMA: 2.0\n",
      "      FOCAL_USE_SIGMOID: True\n",
      "      FOCAL_WEIGHT: 1.0\n",
      "    MASK_CHANNELS: 128\n",
      "    MASK_IN_CHANNELS: 256\n",
      "    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    MASK_THR: 0.5\n",
      "    MAX_PER_IMG: 100\n",
      "    NMS_KERNEL: gaussian\n",
      "    NMS_PRE: 500\n",
      "    NMS_SIGMA: 2\n",
      "    NMS_TYPE: matrix\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 22\n",
      "    NUM_GRIDS: [40, 36, 24, 16, 12]\n",
      "    NUM_INSTANCE_CONVS: 4\n",
      "    NUM_KERNELS: 256\n",
      "    NUM_MASKS: 256\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THR: 0.1\n",
      "    SIGMA: 0.2\n",
      "    TYPE_DCN: DCN\n",
      "    UPDATE_THR: 0.05\n",
      "    USE_COORD_CONV: True\n",
      "    USE_DCN_IN_INSTANCE: False\n",
      "  TOP_MODULE:\n",
      "    DIM: 16\n",
      "    NAME: conv\n",
      "  VOVNET:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    CONV_BODY: V-39-eSE\n",
      "    NORM: FrozenBN\n",
      "    OUT_CHANNELS: 256\n",
      "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
      "  WEIGHTS: /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth\n",
      "OUTPUT_DIR: /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 200\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 6\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 4500\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (3000, 4000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 400\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('trashcan_instance_val',)\n",
      "  TRAIN: ('trashcan_instance_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    CROP_INSTANCE: True\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  HFLIP_TRAIN: True\n",
      "  MASK_FORMAT: bitmask\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 64, 128, 256, 512]]\n",
      "  BACKBONE:\n",
      "    ANTI_ALIAS: False\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  BASIS_MODULE:\n",
      "    ANN_SET: coco\n",
      "    COMMON_STRIDE: 8\n",
      "    CONVS_DIM: 128\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5']\n",
      "    LOSS_ON: False\n",
      "    LOSS_WEIGHT: 0.3\n",
      "    NAME: ProtoNet\n",
      "    NORM: SyncBN\n",
      "    NUM_BASES: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 3\n",
      "  BATEXT:\n",
      "    CANONICAL_SIZE: 96\n",
      "    CONV_DIM: 256\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4']\n",
      "    NUM_CHARS: 25\n",
      "    NUM_CONV: 2\n",
      "    POOLER_RESOLUTION: (8, 32)\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625)\n",
      "    RECOGNITION_LOSS: ctc\n",
      "    RECOGNIZER: attn\n",
      "    SAMPLING_RATIO: 1\n",
      "    VOC_SIZE: 96\n",
      "  BLENDMASK:\n",
      "    ATTN_SIZE: 14\n",
      "    BOTTOM_RESOLUTION: 56\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "    POOLER_SAMPLING_RATIO: 1\n",
      "    POOLER_SCALES: (0.25,)\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    TOP_INTERP: bilinear\n",
      "    VISUALIZE: False\n",
      "  BOXINST:\n",
      "    BOTTOM_PIXELS_REMOVED: 10\n",
      "    ENABLED: False\n",
      "    PAIRWISE:\n",
      "      COLOR_THRESH: 0.3\n",
      "      DILATION: 2\n",
      "      SIZE: 3\n",
      "      WARMUP_ITERS: 10000\n",
      "  BiFPN:\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    NUM_REPEATS: 6\n",
      "    OUT_CHANNELS: 160\n",
      "  CONDINST:\n",
      "    BOTTOM_PIXELS_REMOVED: -1\n",
      "    MASK_BRANCH:\n",
      "      CHANNELS: 128\n",
      "      IN_FEATURES: ['p3', 'p4', 'p5']\n",
      "      NORM: BN\n",
      "      NUM_CONVS: 4\n",
      "      OUT_CHANNELS: 8\n",
      "      SEMANTIC_LOSS_ON: False\n",
      "    MASK_HEAD:\n",
      "      CHANNELS: 8\n",
      "      DISABLE_REL_COORDS: False\n",
      "      NUM_LAYERS: 3\n",
      "      USE_FP16: False\n",
      "    MASK_OUT_STRIDE: 4\n",
      "    MAX_PROPOSALS: -1\n",
      "    TOPK_PROPOSALS_PER_IM: -1\n",
      "  DEVICE: cuda\n",
      "  DLA:\n",
      "    CONV_BODY: DLA34\n",
      "    NORM: FrozenBN\n",
      "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
      "  FCOS:\n",
      "    BOX_QUALITY: ctrness\n",
      "    CENTER_SAMPLE: True\n",
      "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
      "    INFERENCE_TH_TEST: 0.05\n",
      "    INFERENCE_TH_TRAIN: 0.05\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    LOC_LOSS_TYPE: giou\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    LOSS_NORMALIZER_CLS: fg\n",
      "    LOSS_WEIGHT_CLS: 1.0\n",
      "    NMS_TH: 0.6\n",
      "    NORM: GN\n",
      "    NUM_BOX_CONVS: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CLS_CONVS: 4\n",
      "    NUM_SHARE_CONVS: 0\n",
      "    POST_NMS_TOPK_TEST: 100\n",
      "    POST_NMS_TOPK_TRAIN: 100\n",
      "    POS_RADIUS: 1.5\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
      "    THRESH_WITH_CTR: False\n",
      "    TOP_LEVELS: 2\n",
      "    USE_DEFORMABLE: False\n",
      "    USE_RELU: True\n",
      "    USE_SCALE: True\n",
      "    YIELD_PROPOSAL: False\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  MEInst:\n",
      "    AGNOSTIC: True\n",
      "    CENTER_SAMPLE: True\n",
      "    DIM_MASK: 60\n",
      "    FLAG_PARAMETERS: False\n",
      "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
      "    GCN_KERNEL_SIZE: 9\n",
      "    INFERENCE_TH_TEST: 0.05\n",
      "    INFERENCE_TH_TRAIN: 0.05\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    LAST_DEFORMABLE: False\n",
      "    LOC_LOSS_TYPE: giou\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    LOSS_ON_MASK: False\n",
      "    MASK_LOSS_TYPE: mse\n",
      "    MASK_ON: True\n",
      "    MASK_SIZE: 28\n",
      "    NMS_TH: 0.6\n",
      "    NORM: GN\n",
      "    NUM_BOX_CONVS: 4\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CLS_CONVS: 4\n",
      "    NUM_MASK_CONVS: 4\n",
      "    NUM_SHARE_CONVS: 0\n",
      "    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz\n",
      "    POST_NMS_TOPK_TEST: 100\n",
      "    POST_NMS_TOPK_TRAIN: 100\n",
      "    POS_RADIUS: 1.5\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SIGMOID: True\n",
      "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
      "    THRESH_WITH_CTR: False\n",
      "    TOP_LEVELS: 2\n",
      "    TYPE_DEFORMABLE: DCNv1\n",
      "    USE_DEFORMABLE: False\n",
      "    USE_GCN_IN_MASK: False\n",
      "    USE_RELU: True\n",
      "    USE_SCALE: True\n",
      "    WHITEN: True\n",
      "  META_ARCHITECTURE: SOLOv2\n",
      "  MOBILENET: False\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_INTERVAL: 1\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  SOLOV2:\n",
      "    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]\n",
      "    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))\n",
      "    INSTANCE_CHANNELS: 512\n",
      "    INSTANCE_IN_CHANNELS: 256\n",
      "    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    LOSS:\n",
      "      DICE_WEIGHT: 3.0\n",
      "      FOCAL_ALPHA: 0.25\n",
      "      FOCAL_GAMMA: 2.0\n",
      "      FOCAL_USE_SIGMOID: True\n",
      "      FOCAL_WEIGHT: 1.0\n",
      "    MASK_CHANNELS: 128\n",
      "    MASK_IN_CHANNELS: 256\n",
      "    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    MASK_THR: 0.5\n",
      "    MAX_PER_IMG: 100\n",
      "    NMS_KERNEL: gaussian\n",
      "    NMS_PRE: 500\n",
      "    NMS_SIGMA: 2\n",
      "    NMS_TYPE: matrix\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 22\n",
      "    NUM_GRIDS: [40, 36, 24, 16, 12]\n",
      "    NUM_INSTANCE_CONVS: 4\n",
      "    NUM_KERNELS: 256\n",
      "    NUM_MASKS: 256\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THR: 0.1\n",
      "    SIGMA: 0.2\n",
      "    TYPE_DCN: DCN\n",
      "    UPDATE_THR: 0.05\n",
      "    USE_COORD_CONV: True\n",
      "    USE_DCN_IN_INSTANCE: False\n",
      "  TOP_MODULE:\n",
      "    DIM: 16\n",
      "    NAME: conv\n",
      "  VOVNET:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    CONV_BODY: V-39-eSE\n",
      "    NORM: FrozenBN\n",
      "    OUT_CHANNELS: 256\n",
      "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
      "  WEIGHTS: /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth\n",
      "OUTPUT_DIR: /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 200\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 6\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 4500\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (3000, 4000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 400\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mFull config saved to /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/config.yaml\n",
      "\u001b[32m[05/18 00:37:17 detectron2]: \u001b[0mFull config saved to /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/config.yaml\n",
      "\u001b[32m[05/18 00:37:17 d2.utils.env]: \u001b[0mUsing a generated random seed 17833192\n",
      "\u001b[32m[05/18 00:37:17 d2.utils.env]: \u001b[0mUsing a generated random seed 17833192\n",
      "\u001b[32m[05/18 00:37:18 d2.engine.defaults]: \u001b[0mModel:\n",
      "SOLOv2(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ins_head): SOLOv2InsHead(\n",
      "    (cate_tower): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (kernel_tower): Sequential(\n",
      "      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (cate_pred): Conv2d(512, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (mask_head): SOLOv2MaskHead(\n",
      "    (convs_all_levels): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "    )\n",
      "    (conv_pred): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/18 00:37:18 d2.engine.defaults]: \u001b[0mModel:\n",
      "SOLOv2(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ins_head): SOLOv2InsHead(\n",
      "    (cate_tower): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (kernel_tower): Sequential(\n",
      "      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "    )\n",
      "    (cate_pred): Conv2d(512, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (mask_head): SOLOv2MaskHead(\n",
      "    (convs_all_levels): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (conv0): Sequential(\n",
      "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (conv2): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "    )\n",
      "    (conv_pred): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/18 00:37:18 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth\n",
      "\u001b[32m[05/18 00:37:18 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth\n",
      "\u001b[32m[05/18 00:37:19 d2.data.datasets.coco]: \u001b[0mLoaded 1889 images in COCO format from /home/outletters/trashcan/Augmented/val_annotation.json\n",
      "\u001b[32m[05/18 00:37:19 d2.data.datasets.coco]: \u001b[0mLoaded 1889 images in COCO format from /home/outletters/trashcan/Augmented/val_annotation.json\n",
      "\u001b[32m[05/18 00:37:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/18 00:37:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[05/18 00:37:19 d2.data.common]: \u001b[0mSerializing 1889 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/18 00:37:19 d2.data.common]: \u001b[0mSerializing 1889 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/18 00:37:19 d2.data.common]: \u001b[0mSerialized dataset takes 2.68 MiB\n",
      "\u001b[32m[05/18 00:37:19 d2.data.common]: \u001b[0mSerialized dataset takes 2.68 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/18 00:37:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/18 00:37:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[05/18 00:37:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 1889 images\n",
      "\u001b[32m[05/18 00:37:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 1889 images\n",
      "\u001b[32m[05/18 00:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/1889. 0.7313 s / img. ETA=0:24:00\n",
      "\u001b[32m[05/18 00:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/1889. 0.7313 s / img. ETA=0:24:00\n",
      "\u001b[32m[05/18 00:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 18/1889. 0.7278 s / img. ETA=0:23:47\n",
      "\u001b[32m[05/18 00:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 18/1889. 0.7278 s / img. ETA=0:23:47\n",
      "\u001b[32m[05/18 00:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 25/1889. 0.7444 s / img. ETA=0:24:10\n",
      "\u001b[32m[05/18 00:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 25/1889. 0.7444 s / img. ETA=0:24:10\n",
      "\u001b[32m[05/18 00:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 32/1889. 0.7505 s / img. ETA=0:24:14\n",
      "\u001b[32m[05/18 00:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 32/1889. 0.7505 s / img. ETA=0:24:14\n",
      "\u001b[32m[05/18 00:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 38/1889. 0.7845 s / img. ETA=0:25:12\n",
      "\u001b[32m[05/18 00:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 38/1889. 0.7845 s / img. ETA=0:25:12\n",
      "\u001b[32m[05/18 00:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 44/1889. 0.8012 s / img. ETA=0:25:37\n",
      "\u001b[32m[05/18 00:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 44/1889. 0.8012 s / img. ETA=0:25:37\n",
      "\u001b[32m[05/18 00:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 51/1889. 0.7896 s / img. ETA=0:25:10\n",
      "\u001b[32m[05/18 00:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 51/1889. 0.7896 s / img. ETA=0:25:10\n",
      "\u001b[32m[05/18 00:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 58/1889. 0.7851 s / img. ETA=0:24:56\n",
      "\u001b[32m[05/18 00:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 58/1889. 0.7851 s / img. ETA=0:24:56\n",
      "\u001b[32m[05/18 00:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 65/1889. 0.7738 s / img. ETA=0:24:30\n",
      "\u001b[32m[05/18 00:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 65/1889. 0.7738 s / img. ETA=0:24:30\n",
      "\u001b[32m[05/18 00:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 71/1889. 0.7774 s / img. ETA=0:24:31\n",
      "\u001b[32m[05/18 00:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 71/1889. 0.7774 s / img. ETA=0:24:31\n",
      "\u001b[32m[05/18 00:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 78/1889. 0.7784 s / img. ETA=0:24:28\n",
      "\u001b[32m[05/18 00:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 78/1889. 0.7784 s / img. ETA=0:24:28\n",
      "\u001b[32m[05/18 00:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 84/1889. 0.7816 s / img. ETA=0:24:31\n",
      "\u001b[32m[05/18 00:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 84/1889. 0.7816 s / img. ETA=0:24:31\n",
      "\u001b[32m[05/18 00:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 91/1889. 0.7825 s / img. ETA=0:24:27\n",
      "\u001b[32m[05/18 00:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 91/1889. 0.7825 s / img. ETA=0:24:27\n",
      "\u001b[32m[05/18 00:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 97/1889. 0.7853 s / img. ETA=0:24:27\n",
      "\u001b[32m[05/18 00:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 97/1889. 0.7853 s / img. ETA=0:24:27\n",
      "\u001b[32m[05/18 00:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 104/1889. 0.7830 s / img. ETA=0:24:17\n",
      "\u001b[32m[05/18 00:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 104/1889. 0.7830 s / img. ETA=0:24:17\n",
      "\u001b[32m[05/18 00:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 111/1889. 0.7844 s / img. ETA=0:24:13\n",
      "\u001b[32m[05/18 00:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 111/1889. 0.7844 s / img. ETA=0:24:13\n",
      "\u001b[32m[05/18 00:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 118/1889. 0.7811 s / img. ETA=0:24:02\n",
      "\u001b[32m[05/18 00:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 118/1889. 0.7811 s / img. ETA=0:24:02\n",
      "\u001b[32m[05/18 00:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 124/1889. 0.7841 s / img. ETA=0:24:02\n",
      "\u001b[32m[05/18 00:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 124/1889. 0.7841 s / img. ETA=0:24:02\n",
      "\u001b[32m[05/18 00:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 130/1889. 0.7867 s / img. ETA=0:24:01\n",
      "\u001b[32m[05/18 00:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 130/1889. 0.7867 s / img. ETA=0:24:01\n",
      "\u001b[32m[05/18 00:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 137/1889. 0.7858 s / img. ETA=0:23:54\n",
      "\u001b[32m[05/18 00:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 137/1889. 0.7858 s / img. ETA=0:23:54\n",
      "\u001b[32m[05/18 00:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 144/1889. 0.7804 s / img. ETA=0:23:39\n",
      "\u001b[32m[05/18 00:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 144/1889. 0.7804 s / img. ETA=0:23:39\n",
      "\u001b[32m[05/18 00:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 151/1889. 0.7766 s / img. ETA=0:23:27\n",
      "\u001b[32m[05/18 00:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 151/1889. 0.7766 s / img. ETA=0:23:27\n",
      "\u001b[32m[05/18 00:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 158/1889. 0.7763 s / img. ETA=0:23:21\n",
      "\u001b[32m[05/18 00:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 158/1889. 0.7763 s / img. ETA=0:23:21\n",
      "\u001b[32m[05/18 00:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 165/1889. 0.7730 s / img. ETA=0:23:09\n",
      "\u001b[32m[05/18 00:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 165/1889. 0.7730 s / img. ETA=0:23:09\n",
      "\u001b[32m[05/18 00:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 172/1889. 0.7711 s / img. ETA=0:23:01\n",
      "\u001b[32m[05/18 00:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 172/1889. 0.7711 s / img. ETA=0:23:01\n",
      "\u001b[32m[05/18 00:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 179/1889. 0.7691 s / img. ETA=0:22:52\n",
      "\u001b[32m[05/18 00:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 179/1889. 0.7691 s / img. ETA=0:22:52\n",
      "\u001b[32m[05/18 00:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 186/1889. 0.7688 s / img. ETA=0:22:45\n",
      "\u001b[32m[05/18 00:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 186/1889. 0.7688 s / img. ETA=0:22:45\n",
      "\u001b[32m[05/18 00:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 193/1889. 0.7691 s / img. ETA=0:22:40\n",
      "\u001b[32m[05/18 00:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 193/1889. 0.7691 s / img. ETA=0:22:40\n",
      "\u001b[32m[05/18 00:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 200/1889. 0.7681 s / img. ETA=0:22:33\n",
      "\u001b[32m[05/18 00:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 200/1889. 0.7681 s / img. ETA=0:22:33\n",
      "\u001b[32m[05/18 00:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 207/1889. 0.7651 s / img. ETA=0:22:22\n",
      "\u001b[32m[05/18 00:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 207/1889. 0.7651 s / img. ETA=0:22:22\n",
      "\u001b[32m[05/18 00:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 214/1889. 0.7648 s / img. ETA=0:22:16\n",
      "\u001b[32m[05/18 00:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 214/1889. 0.7648 s / img. ETA=0:22:16\n",
      "\u001b[32m[05/18 00:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 221/1889. 0.7658 s / img. ETA=0:22:12\n",
      "\u001b[32m[05/18 00:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 221/1889. 0.7658 s / img. ETA=0:22:12\n",
      "\u001b[32m[05/18 00:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 228/1889. 0.7657 s / img. ETA=0:22:06\n",
      "\u001b[32m[05/18 00:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 228/1889. 0.7657 s / img. ETA=0:22:06\n",
      "\u001b[32m[05/18 00:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 235/1889. 0.7659 s / img. ETA=0:22:01\n",
      "\u001b[32m[05/18 00:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 235/1889. 0.7659 s / img. ETA=0:22:01\n",
      "\u001b[32m[05/18 00:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 242/1889. 0.7661 s / img. ETA=0:21:56\n",
      "\u001b[32m[05/18 00:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 242/1889. 0.7661 s / img. ETA=0:21:56\n",
      "\u001b[32m[05/18 00:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 248/1889. 0.7674 s / img. ETA=0:21:53\n",
      "\u001b[32m[05/18 00:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 248/1889. 0.7674 s / img. ETA=0:21:53\n",
      "\u001b[32m[05/18 00:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 255/1889. 0.7671 s / img. ETA=0:21:47\n",
      "\u001b[32m[05/18 00:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 255/1889. 0.7671 s / img. ETA=0:21:47\n",
      "\u001b[32m[05/18 00:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 261/1889. 0.7690 s / img. ETA=0:21:45\n",
      "\u001b[32m[05/18 00:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 261/1889. 0.7690 s / img. ETA=0:21:45\n",
      "\u001b[32m[05/18 00:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 269/1889. 0.7660 s / img. ETA=0:21:34\n",
      "\u001b[32m[05/18 00:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 269/1889. 0.7660 s / img. ETA=0:21:34\n",
      "\u001b[32m[05/18 00:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 276/1889. 0.7661 s / img. ETA=0:21:28\n",
      "\u001b[32m[05/18 00:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 276/1889. 0.7661 s / img. ETA=0:21:28\n",
      "\u001b[32m[05/18 00:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 283/1889. 0.7669 s / img. ETA=0:21:24\n",
      "\u001b[32m[05/18 00:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 283/1889. 0.7669 s / img. ETA=0:21:24\n",
      "\u001b[32m[05/18 00:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 290/1889. 0.7675 s / img. ETA=0:21:19\n",
      "\u001b[32m[05/18 00:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 290/1889. 0.7675 s / img. ETA=0:21:19\n",
      "\u001b[32m[05/18 00:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 297/1889. 0.7659 s / img. ETA=0:21:11\n",
      "\u001b[32m[05/18 00:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 297/1889. 0.7659 s / img. ETA=0:21:11\n",
      "\u001b[32m[05/18 00:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 303/1889. 0.7672 s / img. ETA=0:21:08\n",
      "\u001b[32m[05/18 00:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 303/1889. 0.7672 s / img. ETA=0:21:08\n",
      "\u001b[32m[05/18 00:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 310/1889. 0.7672 s / img. ETA=0:21:03\n",
      "\u001b[32m[05/18 00:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 310/1889. 0.7672 s / img. ETA=0:21:03\n",
      "\u001b[32m[05/18 00:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 317/1889. 0.7654 s / img. ETA=0:20:54\n",
      "\u001b[32m[05/18 00:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 317/1889. 0.7654 s / img. ETA=0:20:54\n",
      "\u001b[32m[05/18 00:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 324/1889. 0.7646 s / img. ETA=0:20:48\n",
      "\u001b[32m[05/18 00:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 324/1889. 0.7646 s / img. ETA=0:20:48\n",
      "\u001b[32m[05/18 00:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 331/1889. 0.7643 s / img. ETA=0:20:42\n",
      "\u001b[32m[05/18 00:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 331/1889. 0.7643 s / img. ETA=0:20:42\n",
      "\u001b[32m[05/18 00:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 338/1889. 0.7646 s / img. ETA=0:20:36\n",
      "\u001b[32m[05/18 00:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 338/1889. 0.7646 s / img. ETA=0:20:36\n",
      "\u001b[32m[05/18 00:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 345/1889. 0.7642 s / img. ETA=0:20:30\n",
      "\u001b[32m[05/18 00:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 345/1889. 0.7642 s / img. ETA=0:20:30\n",
      "\u001b[32m[05/18 00:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 352/1889. 0.7632 s / img. ETA=0:20:23\n",
      "\u001b[32m[05/18 00:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 352/1889. 0.7632 s / img. ETA=0:20:23\n",
      "\u001b[32m[05/18 00:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 359/1889. 0.7629 s / img. ETA=0:20:17\n",
      "\u001b[32m[05/18 00:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 359/1889. 0.7629 s / img. ETA=0:20:17\n",
      "\u001b[32m[05/18 00:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 366/1889. 0.7634 s / img. ETA=0:20:12\n",
      "\u001b[32m[05/18 00:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 366/1889. 0.7634 s / img. ETA=0:20:12\n",
      "\u001b[32m[05/18 00:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 373/1889. 0.7634 s / img. ETA=0:20:07\n",
      "\u001b[32m[05/18 00:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 373/1889. 0.7634 s / img. ETA=0:20:07\n",
      "\u001b[32m[05/18 00:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 379/1889. 0.7664 s / img. ETA=0:20:07\n",
      "\u001b[32m[05/18 00:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 379/1889. 0.7664 s / img. ETA=0:20:07\n",
      "\u001b[32m[05/18 00:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 386/1889. 0.7648 s / img. ETA=0:19:59\n",
      "\u001b[32m[05/18 00:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 386/1889. 0.7648 s / img. ETA=0:19:59\n",
      "\u001b[32m[05/18 00:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 392/1889. 0.7656 s / img. ETA=0:19:55\n",
      "\u001b[32m[05/18 00:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 392/1889. 0.7656 s / img. ETA=0:19:55\n",
      "\u001b[32m[05/18 00:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 398/1889. 0.7662 s / img. ETA=0:19:51\n",
      "\u001b[32m[05/18 00:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 398/1889. 0.7662 s / img. ETA=0:19:51\n",
      "\u001b[32m[05/18 00:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 404/1889. 0.7670 s / img. ETA=0:19:47\n",
      "\u001b[32m[05/18 00:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 404/1889. 0.7670 s / img. ETA=0:19:47\n",
      "\u001b[32m[05/18 00:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 412/1889. 0.7652 s / img. ETA=0:19:38\n",
      "\u001b[32m[05/18 00:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 412/1889. 0.7652 s / img. ETA=0:19:38\n",
      "\u001b[32m[05/18 00:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 418/1889. 0.7659 s / img. ETA=0:19:35\n",
      "\u001b[32m[05/18 00:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 418/1889. 0.7659 s / img. ETA=0:19:35\n",
      "\u001b[32m[05/18 00:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 425/1889. 0.7654 s / img. ETA=0:19:28\n",
      "\u001b[32m[05/18 00:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 425/1889. 0.7654 s / img. ETA=0:19:28\n",
      "\u001b[32m[05/18 00:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 431/1889. 0.7660 s / img. ETA=0:19:24\n",
      "\u001b[32m[05/18 00:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 431/1889. 0.7660 s / img. ETA=0:19:24\n",
      "\u001b[32m[05/18 00:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 439/1889. 0.7641 s / img. ETA=0:19:15\n",
      "\u001b[32m[05/18 00:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 439/1889. 0.7641 s / img. ETA=0:19:15\n",
      "\u001b[32m[05/18 00:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 445/1889. 0.7650 s / img. ETA=0:19:12\n",
      "\u001b[32m[05/18 00:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 445/1889. 0.7650 s / img. ETA=0:19:12\n",
      "\u001b[32m[05/18 00:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 452/1889. 0.7647 s / img. ETA=0:19:06\n",
      "\u001b[32m[05/18 00:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 452/1889. 0.7647 s / img. ETA=0:19:06\n",
      "\u001b[32m[05/18 00:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 459/1889. 0.7651 s / img. ETA=0:19:01\n",
      "\u001b[32m[05/18 00:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 459/1889. 0.7651 s / img. ETA=0:19:01\n",
      "\u001b[32m[05/18 00:43:32 d2.evaluation.evaluator]: \u001b[0mInference done 466/1889. 0.7658 s / img. ETA=0:18:56\n",
      "\u001b[32m[05/18 00:43:32 d2.evaluation.evaluator]: \u001b[0mInference done 466/1889. 0.7658 s / img. ETA=0:18:56\n",
      "\u001b[32m[05/18 00:43:37 d2.evaluation.evaluator]: \u001b[0mInference done 473/1889. 0.7650 s / img. ETA=0:18:50\n",
      "\u001b[32m[05/18 00:43:37 d2.evaluation.evaluator]: \u001b[0mInference done 473/1889. 0.7650 s / img. ETA=0:18:50\n",
      "\u001b[32m[05/18 00:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 480/1889. 0.7653 s / img. ETA=0:18:44\n",
      "\u001b[32m[05/18 00:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 480/1889. 0.7653 s / img. ETA=0:18:44\n",
      "\u001b[32m[05/18 00:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 486/1889. 0.7660 s / img. ETA=0:18:40\n",
      "\u001b[32m[05/18 00:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 486/1889. 0.7660 s / img. ETA=0:18:40\n",
      "\u001b[32m[05/18 00:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 492/1889. 0.7667 s / img. ETA=0:18:37\n",
      "\u001b[32m[05/18 00:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 492/1889. 0.7667 s / img. ETA=0:18:37\n",
      "\u001b[32m[05/18 00:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 499/1889. 0.7662 s / img. ETA=0:18:30\n",
      "\u001b[32m[05/18 00:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 499/1889. 0.7662 s / img. ETA=0:18:30\n",
      "\u001b[32m[05/18 00:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 506/1889. 0.7653 s / img. ETA=0:18:24\n",
      "\u001b[32m[05/18 00:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 506/1889. 0.7653 s / img. ETA=0:18:24\n",
      "\u001b[32m[05/18 00:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 513/1889. 0.7657 s / img. ETA=0:18:18\n",
      "\u001b[32m[05/18 00:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 513/1889. 0.7657 s / img. ETA=0:18:18\n",
      "\u001b[32m[05/18 00:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 520/1889. 0.7660 s / img. ETA=0:18:13\n",
      "\u001b[32m[05/18 00:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 520/1889. 0.7660 s / img. ETA=0:18:13\n",
      "\u001b[32m[05/18 00:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 527/1889. 0.7654 s / img. ETA=0:18:07\n",
      "\u001b[32m[05/18 00:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 527/1889. 0.7654 s / img. ETA=0:18:07\n",
      "\u001b[32m[05/18 00:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 535/1889. 0.7640 s / img. ETA=0:17:59\n",
      "\u001b[32m[05/18 00:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 535/1889. 0.7640 s / img. ETA=0:17:59\n",
      "\u001b[32m[05/18 00:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 542/1889. 0.7629 s / img. ETA=0:17:52\n",
      "\u001b[32m[05/18 00:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 542/1889. 0.7629 s / img. ETA=0:17:52\n",
      "\u001b[32m[05/18 00:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 548/1889. 0.7637 s / img. ETA=0:17:48\n",
      "\u001b[32m[05/18 00:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 548/1889. 0.7637 s / img. ETA=0:17:48\n",
      "\u001b[32m[05/18 00:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 554/1889. 0.7642 s / img. ETA=0:17:44\n",
      "\u001b[32m[05/18 00:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 554/1889. 0.7642 s / img. ETA=0:17:44\n",
      "\u001b[32m[05/18 00:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 561/1889. 0.7644 s / img. ETA=0:17:39\n",
      "\u001b[32m[05/18 00:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 561/1889. 0.7644 s / img. ETA=0:17:39\n",
      "\u001b[32m[05/18 00:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 568/1889. 0.7643 s / img. ETA=0:17:33\n",
      "\u001b[32m[05/18 00:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 568/1889. 0.7643 s / img. ETA=0:17:33\n",
      "\u001b[32m[05/18 00:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 574/1889. 0.7648 s / img. ETA=0:17:29\n",
      "\u001b[32m[05/18 00:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 574/1889. 0.7648 s / img. ETA=0:17:29\n",
      "\u001b[32m[05/18 00:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 581/1889. 0.7650 s / img. ETA=0:17:24\n",
      "\u001b[32m[05/18 00:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 581/1889. 0.7650 s / img. ETA=0:17:24\n",
      "\u001b[32m[05/18 00:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 588/1889. 0.7650 s / img. ETA=0:17:18\n",
      "\u001b[32m[05/18 00:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 588/1889. 0.7650 s / img. ETA=0:17:18\n",
      "\u001b[32m[05/18 00:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 595/1889. 0.7648 s / img. ETA=0:17:12\n",
      "\u001b[32m[05/18 00:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 595/1889. 0.7648 s / img. ETA=0:17:12\n",
      "\u001b[32m[05/18 00:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 602/1889. 0.7640 s / img. ETA=0:17:05\n",
      "\u001b[32m[05/18 00:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 602/1889. 0.7640 s / img. ETA=0:17:05\n",
      "\u001b[32m[05/18 00:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 609/1889. 0.7644 s / img. ETA=0:17:00\n",
      "\u001b[32m[05/18 00:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 609/1889. 0.7644 s / img. ETA=0:17:00\n",
      "\u001b[32m[05/18 00:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 616/1889. 0.7643 s / img. ETA=0:16:55\n",
      "\u001b[32m[05/18 00:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 616/1889. 0.7643 s / img. ETA=0:16:55\n",
      "\u001b[32m[05/18 00:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 622/1889. 0.7649 s / img. ETA=0:16:51\n",
      "\u001b[32m[05/18 00:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 622/1889. 0.7649 s / img. ETA=0:16:51\n",
      "\u001b[32m[05/18 00:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 629/1889. 0.7640 s / img. ETA=0:16:44\n",
      "\u001b[32m[05/18 00:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 629/1889. 0.7640 s / img. ETA=0:16:44\n",
      "\u001b[32m[05/18 00:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 636/1889. 0.7643 s / img. ETA=0:16:39\n",
      "\u001b[32m[05/18 00:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 636/1889. 0.7643 s / img. ETA=0:16:39\n",
      "\u001b[32m[05/18 00:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 643/1889. 0.7644 s / img. ETA=0:16:33\n",
      "\u001b[32m[05/18 00:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 643/1889. 0.7644 s / img. ETA=0:16:33\n",
      "\u001b[32m[05/18 00:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 650/1889. 0.7636 s / img. ETA=0:16:27\n",
      "\u001b[32m[05/18 00:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 650/1889. 0.7636 s / img. ETA=0:16:27\n",
      "\u001b[32m[05/18 00:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 657/1889. 0.7638 s / img. ETA=0:16:21\n",
      "\u001b[32m[05/18 00:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 657/1889. 0.7638 s / img. ETA=0:16:21\n",
      "\u001b[32m[05/18 00:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 663/1889. 0.7644 s / img. ETA=0:16:17\n",
      "\u001b[32m[05/18 00:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 663/1889. 0.7644 s / img. ETA=0:16:17\n",
      "\u001b[32m[05/18 00:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 670/1889. 0.7646 s / img. ETA=0:16:12\n",
      "\u001b[32m[05/18 00:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 670/1889. 0.7646 s / img. ETA=0:16:12\n",
      "\u001b[32m[05/18 00:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 676/1889. 0.7650 s / img. ETA=0:16:08\n",
      "\u001b[32m[05/18 00:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 676/1889. 0.7650 s / img. ETA=0:16:08\n",
      "\u001b[32m[05/18 00:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 683/1889. 0.7650 s / img. ETA=0:16:02\n",
      "\u001b[32m[05/18 00:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 683/1889. 0.7650 s / img. ETA=0:16:02\n",
      "\u001b[32m[05/18 00:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 689/1889. 0.7654 s / img. ETA=0:15:58\n",
      "\u001b[32m[05/18 00:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 689/1889. 0.7654 s / img. ETA=0:15:58\n",
      "\u001b[32m[05/18 00:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 695/1889. 0.7659 s / img. ETA=0:15:53\n",
      "\u001b[32m[05/18 00:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 695/1889. 0.7659 s / img. ETA=0:15:53\n",
      "\u001b[32m[05/18 00:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 701/1889. 0.7662 s / img. ETA=0:15:49\n",
      "\u001b[32m[05/18 00:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 701/1889. 0.7662 s / img. ETA=0:15:49\n",
      "\u001b[32m[05/18 00:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 708/1889. 0.7662 s / img. ETA=0:15:43\n",
      "\u001b[32m[05/18 00:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 708/1889. 0.7662 s / img. ETA=0:15:43\n",
      "\u001b[32m[05/18 00:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 714/1889. 0.7667 s / img. ETA=0:15:39\n",
      "\u001b[32m[05/18 00:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 714/1889. 0.7667 s / img. ETA=0:15:39\n",
      "\u001b[32m[05/18 00:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 720/1889. 0.7673 s / img. ETA=0:15:35\n",
      "\u001b[32m[05/18 00:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 720/1889. 0.7673 s / img. ETA=0:15:35\n",
      "\u001b[32m[05/18 00:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 727/1889. 0.7673 s / img. ETA=0:15:29\n",
      "\u001b[32m[05/18 00:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 727/1889. 0.7673 s / img. ETA=0:15:29\n",
      "\u001b[32m[05/18 00:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 734/1889. 0.7664 s / img. ETA=0:15:23\n",
      "\u001b[32m[05/18 00:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 734/1889. 0.7664 s / img. ETA=0:15:23\n",
      "\u001b[32m[05/18 00:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 740/1889. 0.7668 s / img. ETA=0:15:18\n",
      "\u001b[32m[05/18 00:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 740/1889. 0.7668 s / img. ETA=0:15:18\n",
      "\u001b[32m[05/18 00:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 747/1889. 0.7666 s / img. ETA=0:15:13\n",
      "\u001b[32m[05/18 00:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 747/1889. 0.7666 s / img. ETA=0:15:13\n",
      "\u001b[32m[05/18 00:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 754/1889. 0.7661 s / img. ETA=0:15:06\n",
      "\u001b[32m[05/18 00:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 754/1889. 0.7661 s / img. ETA=0:15:06\n",
      "\u001b[32m[05/18 00:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 760/1889. 0.7665 s / img. ETA=0:15:02\n",
      "\u001b[32m[05/18 00:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 760/1889. 0.7665 s / img. ETA=0:15:02\n",
      "\u001b[32m[05/18 00:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 768/1889. 0.7655 s / img. ETA=0:14:55\n",
      "\u001b[32m[05/18 00:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 768/1889. 0.7655 s / img. ETA=0:14:55\n",
      "\u001b[32m[05/18 00:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 774/1889. 0.7661 s / img. ETA=0:14:50\n",
      "\u001b[32m[05/18 00:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 774/1889. 0.7661 s / img. ETA=0:14:50\n",
      "\u001b[32m[05/18 00:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 781/1889. 0.7662 s / img. ETA=0:14:45\n",
      "\u001b[32m[05/18 00:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 781/1889. 0.7662 s / img. ETA=0:14:45\n",
      "\u001b[32m[05/18 00:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 788/1889. 0.7659 s / img. ETA=0:14:39\n",
      "\u001b[32m[05/18 00:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 788/1889. 0.7659 s / img. ETA=0:14:39\n",
      "\u001b[32m[05/18 00:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 795/1889. 0.7656 s / img. ETA=0:14:33\n",
      "\u001b[32m[05/18 00:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 795/1889. 0.7656 s / img. ETA=0:14:33\n",
      "\u001b[32m[05/18 00:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 802/1889. 0.7656 s / img. ETA=0:14:28\n",
      "\u001b[32m[05/18 00:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 802/1889. 0.7656 s / img. ETA=0:14:28\n",
      "\u001b[32m[05/18 00:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 808/1889. 0.7661 s / img. ETA=0:14:23\n",
      "\u001b[32m[05/18 00:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 808/1889. 0.7661 s / img. ETA=0:14:23\n",
      "\u001b[32m[05/18 00:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 814/1889. 0.7664 s / img. ETA=0:14:19\n",
      "\u001b[32m[05/18 00:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 814/1889. 0.7664 s / img. ETA=0:14:19\n",
      "\u001b[32m[05/18 00:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 821/1889. 0.7662 s / img. ETA=0:14:13\n",
      "\u001b[32m[05/18 00:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 821/1889. 0.7662 s / img. ETA=0:14:13\n",
      "\u001b[32m[05/18 00:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 827/1889. 0.7665 s / img. ETA=0:14:09\n",
      "\u001b[32m[05/18 00:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 827/1889. 0.7665 s / img. ETA=0:14:09\n",
      "\u001b[32m[05/18 00:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 833/1889. 0.7668 s / img. ETA=0:14:04\n",
      "\u001b[32m[05/18 00:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 833/1889. 0.7668 s / img. ETA=0:14:04\n",
      "\u001b[32m[05/18 00:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 839/1889. 0.7674 s / img. ETA=0:14:00\n",
      "\u001b[32m[05/18 00:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 839/1889. 0.7674 s / img. ETA=0:14:00\n",
      "\u001b[32m[05/18 00:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 846/1889. 0.7672 s / img. ETA=0:13:54\n",
      "\u001b[32m[05/18 00:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 846/1889. 0.7672 s / img. ETA=0:13:54\n",
      "\u001b[32m[05/18 00:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 853/1889. 0.7673 s / img. ETA=0:13:49\n",
      "\u001b[32m[05/18 00:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 853/1889. 0.7673 s / img. ETA=0:13:49\n",
      "\u001b[32m[05/18 00:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 860/1889. 0.7668 s / img. ETA=0:13:43\n",
      "\u001b[32m[05/18 00:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 860/1889. 0.7668 s / img. ETA=0:13:43\n",
      "\u001b[32m[05/18 00:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 867/1889. 0.7661 s / img. ETA=0:13:36\n",
      "\u001b[32m[05/18 00:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 867/1889. 0.7661 s / img. ETA=0:13:36\n",
      "\u001b[32m[05/18 00:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 873/1889. 0.7666 s / img. ETA=0:13:32\n",
      "\u001b[32m[05/18 00:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 873/1889. 0.7666 s / img. ETA=0:13:32\n",
      "\u001b[32m[05/18 00:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 880/1889. 0.7665 s / img. ETA=0:13:26\n",
      "\u001b[32m[05/18 00:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 880/1889. 0.7665 s / img. ETA=0:13:26\n",
      "\u001b[32m[05/18 00:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 887/1889. 0.7663 s / img. ETA=0:13:20\n",
      "\u001b[32m[05/18 00:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 887/1889. 0.7663 s / img. ETA=0:13:20\n",
      "\u001b[32m[05/18 00:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 893/1889. 0.7667 s / img. ETA=0:13:16\n",
      "\u001b[32m[05/18 00:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 893/1889. 0.7667 s / img. ETA=0:13:16\n",
      "\u001b[32m[05/18 00:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 900/1889. 0.7663 s / img. ETA=0:13:10\n",
      "\u001b[32m[05/18 00:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 900/1889. 0.7663 s / img. ETA=0:13:10\n",
      "\u001b[32m[05/18 00:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 907/1889. 0.7662 s / img. ETA=0:13:04\n",
      "\u001b[32m[05/18 00:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 907/1889. 0.7662 s / img. ETA=0:13:04\n",
      "\u001b[32m[05/18 00:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 914/1889. 0.7658 s / img. ETA=0:12:58\n",
      "\u001b[32m[05/18 00:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 914/1889. 0.7658 s / img. ETA=0:12:58\n",
      "\u001b[32m[05/18 00:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 920/1889. 0.7661 s / img. ETA=0:12:54\n",
      "\u001b[32m[05/18 00:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 920/1889. 0.7661 s / img. ETA=0:12:54\n",
      "\u001b[32m[05/18 00:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 927/1889. 0.7658 s / img. ETA=0:12:48\n",
      "\u001b[32m[05/18 00:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 927/1889. 0.7658 s / img. ETA=0:12:48\n",
      "\u001b[32m[05/18 00:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 933/1889. 0.7661 s / img. ETA=0:12:43\n",
      "\u001b[32m[05/18 00:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 933/1889. 0.7661 s / img. ETA=0:12:43\n",
      "\u001b[32m[05/18 00:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 939/1889. 0.7669 s / img. ETA=0:12:39\n",
      "\u001b[32m[05/18 00:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 939/1889. 0.7669 s / img. ETA=0:12:39\n",
      "\u001b[32m[05/18 00:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 945/1889. 0.7672 s / img. ETA=0:12:35\n",
      "\u001b[32m[05/18 00:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 945/1889. 0.7672 s / img. ETA=0:12:35\n",
      "\u001b[32m[05/18 00:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 952/1889. 0.7669 s / img. ETA=0:12:29\n",
      "\u001b[32m[05/18 00:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 952/1889. 0.7669 s / img. ETA=0:12:29\n",
      "\u001b[32m[05/18 00:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 959/1889. 0.7664 s / img. ETA=0:12:23\n",
      "\u001b[32m[05/18 00:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 959/1889. 0.7664 s / img. ETA=0:12:23\n",
      "\u001b[32m[05/18 00:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 965/1889. 0.7668 s / img. ETA=0:12:19\n",
      "\u001b[32m[05/18 00:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 965/1889. 0.7668 s / img. ETA=0:12:19\n",
      "\u001b[32m[05/18 00:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 972/1889. 0.7666 s / img. ETA=0:12:13\n",
      "\u001b[32m[05/18 00:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 972/1889. 0.7666 s / img. ETA=0:12:13\n",
      "\u001b[32m[05/18 00:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 979/1889. 0.7668 s / img. ETA=0:12:07\n",
      "\u001b[32m[05/18 00:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 979/1889. 0.7668 s / img. ETA=0:12:07\n",
      "\u001b[32m[05/18 00:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 986/1889. 0.7671 s / img. ETA=0:12:02\n",
      "\u001b[32m[05/18 00:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 986/1889. 0.7671 s / img. ETA=0:12:02\n",
      "\u001b[32m[05/18 00:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 993/1889. 0.7672 s / img. ETA=0:11:57\n",
      "\u001b[32m[05/18 00:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 993/1889. 0.7672 s / img. ETA=0:11:57\n",
      "\u001b[32m[05/18 00:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 1000/1889. 0.7672 s / img. ETA=0:11:51\n",
      "\u001b[32m[05/18 00:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 1000/1889. 0.7672 s / img. ETA=0:11:51\n",
      "\u001b[32m[05/18 00:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 1007/1889. 0.7669 s / img. ETA=0:11:45\n",
      "\u001b[32m[05/18 00:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 1007/1889. 0.7669 s / img. ETA=0:11:45\n",
      "\u001b[32m[05/18 00:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 1014/1889. 0.7664 s / img. ETA=0:11:39\n",
      "\u001b[32m[05/18 00:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 1014/1889. 0.7664 s / img. ETA=0:11:39\n",
      "\u001b[32m[05/18 00:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 1021/1889. 0.7666 s / img. ETA=0:11:34\n",
      "\u001b[32m[05/18 00:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 1021/1889. 0.7666 s / img. ETA=0:11:34\n",
      "\u001b[32m[05/18 00:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 1027/1889. 0.7670 s / img. ETA=0:11:29\n",
      "\u001b[32m[05/18 00:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 1027/1889. 0.7670 s / img. ETA=0:11:29\n",
      "\u001b[32m[05/18 00:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 1034/1889. 0.7669 s / img. ETA=0:11:23\n",
      "\u001b[32m[05/18 00:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 1034/1889. 0.7669 s / img. ETA=0:11:23\n",
      "\u001b[32m[05/18 00:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 1040/1889. 0.7672 s / img. ETA=0:11:19\n",
      "\u001b[32m[05/18 00:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 1040/1889. 0.7672 s / img. ETA=0:11:19\n",
      "\u001b[32m[05/18 00:51:18 d2.evaluation.evaluator]: \u001b[0mInference done 1047/1889. 0.7670 s / img. ETA=0:11:13\n",
      "\u001b[32m[05/18 00:51:18 d2.evaluation.evaluator]: \u001b[0mInference done 1047/1889. 0.7670 s / img. ETA=0:11:13\n",
      "\u001b[32m[05/18 00:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 1053/1889. 0.7672 s / img. ETA=0:11:09\n",
      "\u001b[32m[05/18 00:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 1053/1889. 0.7672 s / img. ETA=0:11:09\n",
      "\u001b[32m[05/18 00:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 1060/1889. 0.7672 s / img. ETA=0:11:03\n",
      "\u001b[32m[05/18 00:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 1060/1889. 0.7672 s / img. ETA=0:11:03\n",
      "\u001b[32m[05/18 00:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 1067/1889. 0.7670 s / img. ETA=0:10:57\n",
      "\u001b[32m[05/18 00:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 1067/1889. 0.7670 s / img. ETA=0:10:57\n",
      "\u001b[32m[05/18 00:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 1074/1889. 0.7670 s / img. ETA=0:10:51\n",
      "\u001b[32m[05/18 00:51:39 d2.evaluation.evaluator]: \u001b[0mInference done 1074/1889. 0.7670 s / img. ETA=0:10:51\n",
      "\u001b[32m[05/18 00:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 1081/1889. 0.7666 s / img. ETA=0:10:46\n",
      "\u001b[32m[05/18 00:51:44 d2.evaluation.evaluator]: \u001b[0mInference done 1081/1889. 0.7666 s / img. ETA=0:10:46\n",
      "\u001b[32m[05/18 00:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 1088/1889. 0.7664 s / img. ETA=0:10:40\n",
      "\u001b[32m[05/18 00:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 1088/1889. 0.7664 s / img. ETA=0:10:40\n",
      "\u001b[32m[05/18 00:51:55 d2.evaluation.evaluator]: \u001b[0mInference done 1095/1889. 0.7665 s / img. ETA=0:10:34\n",
      "\u001b[32m[05/18 00:51:55 d2.evaluation.evaluator]: \u001b[0mInference done 1095/1889. 0.7665 s / img. ETA=0:10:34\n",
      "\u001b[32m[05/18 00:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 1101/1889. 0.7668 s / img. ETA=0:10:30\n",
      "\u001b[32m[05/18 00:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 1101/1889. 0.7668 s / img. ETA=0:10:30\n",
      "\u001b[32m[05/18 00:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 1107/1889. 0.7670 s / img. ETA=0:10:25\n",
      "\u001b[32m[05/18 00:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 1107/1889. 0.7670 s / img. ETA=0:10:25\n",
      "\u001b[32m[05/18 00:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 1113/1889. 0.7673 s / img. ETA=0:10:21\n",
      "\u001b[32m[05/18 00:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 1113/1889. 0.7673 s / img. ETA=0:10:21\n",
      "\u001b[32m[05/18 00:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 1119/1889. 0.7677 s / img. ETA=0:10:16\n",
      "\u001b[32m[05/18 00:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 1119/1889. 0.7677 s / img. ETA=0:10:16\n",
      "\u001b[32m[05/18 00:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 1126/1889. 0.7679 s / img. ETA=0:10:11\n",
      "\u001b[32m[05/18 00:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 1126/1889. 0.7679 s / img. ETA=0:10:11\n",
      "\u001b[32m[05/18 00:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 1133/1889. 0.7680 s / img. ETA=0:10:05\n",
      "\u001b[32m[05/18 00:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 1133/1889. 0.7680 s / img. ETA=0:10:05\n",
      "\u001b[32m[05/18 00:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 1140/1889. 0.7676 s / img. ETA=0:09:59\n",
      "\u001b[32m[05/18 00:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 1140/1889. 0.7676 s / img. ETA=0:09:59\n",
      "\u001b[32m[05/18 00:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 1147/1889. 0.7678 s / img. ETA=0:09:54\n",
      "\u001b[32m[05/18 00:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 1147/1889. 0.7678 s / img. ETA=0:09:54\n",
      "\u001b[32m[05/18 00:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 1154/1889. 0.7680 s / img. ETA=0:09:48\n",
      "\u001b[32m[05/18 00:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 1154/1889. 0.7680 s / img. ETA=0:09:48\n",
      "\u001b[32m[05/18 00:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 1161/1889. 0.7675 s / img. ETA=0:09:42\n",
      "\u001b[32m[05/18 00:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 1161/1889. 0.7675 s / img. ETA=0:09:42\n",
      "\u001b[32m[05/18 00:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 1167/1889. 0.7677 s / img. ETA=0:09:37\n",
      "\u001b[32m[05/18 00:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 1167/1889. 0.7677 s / img. ETA=0:09:37\n",
      "\u001b[32m[05/18 00:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 1174/1889. 0.7677 s / img. ETA=0:09:32\n",
      "\u001b[32m[05/18 00:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 1174/1889. 0.7677 s / img. ETA=0:09:32\n",
      "\u001b[32m[05/18 00:53:06 d2.evaluation.evaluator]: \u001b[0mInference done 1181/1889. 0.7679 s / img. ETA=0:09:26\n",
      "\u001b[32m[05/18 00:53:06 d2.evaluation.evaluator]: \u001b[0mInference done 1181/1889. 0.7679 s / img. ETA=0:09:26\n",
      "\u001b[32m[05/18 00:53:11 d2.evaluation.evaluator]: \u001b[0mInference done 1187/1889. 0.7682 s / img. ETA=0:09:22\n",
      "\u001b[32m[05/18 00:53:11 d2.evaluation.evaluator]: \u001b[0mInference done 1187/1889. 0.7682 s / img. ETA=0:09:22\n",
      "\u001b[32m[05/18 00:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 1194/1889. 0.7685 s / img. ETA=0:09:16\n",
      "\u001b[32m[05/18 00:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 1194/1889. 0.7685 s / img. ETA=0:09:16\n",
      "\u001b[32m[05/18 00:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 1201/1889. 0.7684 s / img. ETA=0:09:11\n",
      "\u001b[32m[05/18 00:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 1201/1889. 0.7684 s / img. ETA=0:09:11\n",
      "\u001b[32m[05/18 00:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 1208/1889. 0.7682 s / img. ETA=0:09:05\n",
      "\u001b[32m[05/18 00:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 1208/1889. 0.7682 s / img. ETA=0:09:05\n",
      "\u001b[32m[05/18 00:53:33 d2.evaluation.evaluator]: \u001b[0mInference done 1215/1889. 0.7684 s / img. ETA=0:09:00\n",
      "\u001b[32m[05/18 00:53:33 d2.evaluation.evaluator]: \u001b[0mInference done 1215/1889. 0.7684 s / img. ETA=0:09:00\n",
      "\u001b[32m[05/18 00:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 1221/1889. 0.7687 s / img. ETA=0:08:55\n",
      "\u001b[32m[05/18 00:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 1221/1889. 0.7687 s / img. ETA=0:08:55\n",
      "\u001b[32m[05/18 00:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 1227/1889. 0.7689 s / img. ETA=0:08:50\n",
      "\u001b[32m[05/18 00:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 1227/1889. 0.7689 s / img. ETA=0:08:50\n",
      "\u001b[32m[05/18 00:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 1234/1889. 0.7690 s / img. ETA=0:08:45\n",
      "\u001b[32m[05/18 00:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 1234/1889. 0.7690 s / img. ETA=0:08:45\n",
      "\u001b[32m[05/18 00:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 1241/1889. 0.7688 s / img. ETA=0:08:39\n",
      "\u001b[32m[05/18 00:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 1241/1889. 0.7688 s / img. ETA=0:08:39\n",
      "\u001b[32m[05/18 00:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 1248/1889. 0.7686 s / img. ETA=0:08:33\n",
      "\u001b[32m[05/18 00:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 1248/1889. 0.7686 s / img. ETA=0:08:33\n",
      "\u001b[32m[05/18 00:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 1255/1889. 0.7683 s / img. ETA=0:08:27\n",
      "\u001b[32m[05/18 00:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 1255/1889. 0.7683 s / img. ETA=0:08:27\n",
      "\u001b[32m[05/18 00:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 1262/1889. 0.7684 s / img. ETA=0:08:22\n",
      "\u001b[32m[05/18 00:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 1262/1889. 0.7684 s / img. ETA=0:08:22\n",
      "\u001b[32m[05/18 00:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 1268/1889. 0.7686 s / img. ETA=0:08:17\n",
      "\u001b[32m[05/18 00:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 1268/1889. 0.7686 s / img. ETA=0:08:17\n",
      "\u001b[32m[05/18 00:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 1275/1889. 0.7688 s / img. ETA=0:08:12\n",
      "\u001b[32m[05/18 00:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 1275/1889. 0.7688 s / img. ETA=0:08:12\n",
      "\u001b[32m[05/18 00:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 1281/1889. 0.7691 s / img. ETA=0:08:07\n",
      "\u001b[32m[05/18 00:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 1281/1889. 0.7691 s / img. ETA=0:08:07\n",
      "\u001b[32m[05/18 00:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 1287/1889. 0.7694 s / img. ETA=0:08:02\n",
      "\u001b[32m[05/18 00:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 1287/1889. 0.7694 s / img. ETA=0:08:02\n",
      "\u001b[32m[05/18 00:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 1294/1889. 0.7693 s / img. ETA=0:07:57\n",
      "\u001b[32m[05/18 00:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 1294/1889. 0.7693 s / img. ETA=0:07:57\n",
      "\u001b[32m[05/18 00:54:44 d2.evaluation.evaluator]: \u001b[0mInference done 1302/1889. 0.7688 s / img. ETA=0:07:50\n",
      "\u001b[32m[05/18 00:54:44 d2.evaluation.evaluator]: \u001b[0mInference done 1302/1889. 0.7688 s / img. ETA=0:07:50\n",
      "\u001b[32m[05/18 00:54:49 d2.evaluation.evaluator]: \u001b[0mInference done 1309/1889. 0.7688 s / img. ETA=0:07:44\n",
      "\u001b[32m[05/18 00:54:49 d2.evaluation.evaluator]: \u001b[0mInference done 1309/1889. 0.7688 s / img. ETA=0:07:44\n",
      "\u001b[32m[05/18 00:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 1317/1889. 0.7683 s / img. ETA=0:07:38\n",
      "\u001b[32m[05/18 00:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 1317/1889. 0.7683 s / img. ETA=0:07:38\n",
      "\u001b[32m[05/18 00:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 1324/1889. 0.7684 s / img. ETA=0:07:32\n",
      "\u001b[32m[05/18 00:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 1324/1889. 0.7684 s / img. ETA=0:07:32\n",
      "\u001b[32m[05/18 00:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 1331/1889. 0.7683 s / img. ETA=0:07:26\n",
      "\u001b[32m[05/18 00:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 1331/1889. 0.7683 s / img. ETA=0:07:26\n",
      "\u001b[32m[05/18 00:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 1338/1889. 0.7684 s / img. ETA=0:07:21\n",
      "\u001b[32m[05/18 00:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 1338/1889. 0.7684 s / img. ETA=0:07:21\n",
      "\u001b[32m[05/18 00:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 1345/1889. 0.7683 s / img. ETA=0:07:15\n",
      "\u001b[32m[05/18 00:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 1345/1889. 0.7683 s / img. ETA=0:07:15\n",
      "\u001b[32m[05/18 00:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 1351/1889. 0.7686 s / img. ETA=0:07:11\n",
      "\u001b[32m[05/18 00:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 1351/1889. 0.7686 s / img. ETA=0:07:11\n",
      "\u001b[32m[05/18 00:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 1357/1889. 0.7687 s / img. ETA=0:07:06\n",
      "\u001b[32m[05/18 00:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 1357/1889. 0.7687 s / img. ETA=0:07:06\n",
      "\u001b[32m[05/18 00:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 1364/1889. 0.7686 s / img. ETA=0:07:00\n",
      "\u001b[32m[05/18 00:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 1364/1889. 0.7686 s / img. ETA=0:07:00\n",
      "\u001b[32m[05/18 00:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 1371/1889. 0.7687 s / img. ETA=0:06:55\n",
      "\u001b[32m[05/18 00:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 1371/1889. 0.7687 s / img. ETA=0:06:55\n",
      "\u001b[32m[05/18 00:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 1378/1889. 0.7685 s / img. ETA=0:06:49\n",
      "\u001b[32m[05/18 00:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 1378/1889. 0.7685 s / img. ETA=0:06:49\n",
      "\u001b[32m[05/18 00:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 1385/1889. 0.7686 s / img. ETA=0:06:43\n",
      "\u001b[32m[05/18 00:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 1385/1889. 0.7686 s / img. ETA=0:06:43\n",
      "\u001b[32m[05/18 00:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 1392/1889. 0.7685 s / img. ETA=0:06:38\n",
      "\u001b[32m[05/18 00:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 1392/1889. 0.7685 s / img. ETA=0:06:38\n",
      "\u001b[32m[05/18 00:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 1399/1889. 0.7685 s / img. ETA=0:06:32\n",
      "\u001b[32m[05/18 00:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 1399/1889. 0.7685 s / img. ETA=0:06:32\n",
      "\u001b[32m[05/18 00:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 1406/1889. 0.7687 s / img. ETA=0:06:27\n",
      "\u001b[32m[05/18 00:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 1406/1889. 0.7687 s / img. ETA=0:06:27\n",
      "\u001b[32m[05/18 00:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 1412/1889. 0.7690 s / img. ETA=0:06:22\n",
      "\u001b[32m[05/18 00:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 1412/1889. 0.7690 s / img. ETA=0:06:22\n",
      "\u001b[32m[05/18 00:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 1418/1889. 0.7692 s / img. ETA=0:06:17\n",
      "\u001b[32m[05/18 00:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 1418/1889. 0.7692 s / img. ETA=0:06:17\n",
      "\u001b[32m[05/18 00:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 1425/1889. 0.7691 s / img. ETA=0:06:12\n",
      "\u001b[32m[05/18 00:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 1425/1889. 0.7691 s / img. ETA=0:06:12\n",
      "\u001b[32m[05/18 00:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 1432/1889. 0.7693 s / img. ETA=0:06:06\n",
      "\u001b[32m[05/18 00:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 1432/1889. 0.7693 s / img. ETA=0:06:06\n",
      "\u001b[32m[05/18 00:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 1439/1889. 0.7692 s / img. ETA=0:06:00\n",
      "\u001b[32m[05/18 00:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 1439/1889. 0.7692 s / img. ETA=0:06:00\n",
      "\u001b[32m[05/18 00:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 1446/1889. 0.7690 s / img. ETA=0:05:55\n",
      "\u001b[32m[05/18 00:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 1446/1889. 0.7690 s / img. ETA=0:05:55\n",
      "\u001b[32m[05/18 00:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 1453/1889. 0.7691 s / img. ETA=0:05:49\n",
      "\u001b[32m[05/18 00:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 1453/1889. 0.7691 s / img. ETA=0:05:49\n",
      "\u001b[32m[05/18 00:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 1459/1889. 0.7695 s / img. ETA=0:05:44\n",
      "\u001b[32m[05/18 00:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 1459/1889. 0.7695 s / img. ETA=0:05:44\n",
      "\u001b[32m[05/18 00:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 1466/1889. 0.7694 s / img. ETA=0:05:39\n",
      "\u001b[32m[05/18 00:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 1466/1889. 0.7694 s / img. ETA=0:05:39\n",
      "\u001b[32m[05/18 00:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 1472/1889. 0.7696 s / img. ETA=0:05:34\n",
      "\u001b[32m[05/18 00:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 1472/1889. 0.7696 s / img. ETA=0:05:34\n",
      "\u001b[32m[05/18 00:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 1479/1889. 0.7698 s / img. ETA=0:05:28\n",
      "\u001b[32m[05/18 00:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 1479/1889. 0.7698 s / img. ETA=0:05:28\n",
      "\u001b[32m[05/18 00:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 1485/1889. 0.7699 s / img. ETA=0:05:24\n",
      "\u001b[32m[05/18 00:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 1485/1889. 0.7699 s / img. ETA=0:05:24\n",
      "\u001b[32m[05/18 00:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 1492/1889. 0.7697 s / img. ETA=0:05:18\n",
      "\u001b[32m[05/18 00:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 1492/1889. 0.7697 s / img. ETA=0:05:18\n",
      "\u001b[32m[05/18 00:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 1499/1889. 0.7697 s / img. ETA=0:05:12\n",
      "\u001b[32m[05/18 00:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 1499/1889. 0.7697 s / img. ETA=0:05:12\n",
      "\u001b[32m[05/18 00:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 1506/1889. 0.7694 s / img. ETA=0:05:07\n",
      "\u001b[32m[05/18 00:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 1506/1889. 0.7694 s / img. ETA=0:05:07\n",
      "\u001b[32m[05/18 00:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 1513/1889. 0.7693 s / img. ETA=0:05:01\n",
      "\u001b[32m[05/18 00:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 1513/1889. 0.7693 s / img. ETA=0:05:01\n",
      "\u001b[32m[05/18 00:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 1520/1889. 0.7693 s / img. ETA=0:04:55\n",
      "\u001b[32m[05/18 00:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 1520/1889. 0.7693 s / img. ETA=0:04:55\n",
      "\u001b[32m[05/18 00:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 1527/1889. 0.7689 s / img. ETA=0:04:50\n",
      "\u001b[32m[05/18 00:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 1527/1889. 0.7689 s / img. ETA=0:04:50\n",
      "\u001b[32m[05/18 00:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 1534/1889. 0.7688 s / img. ETA=0:04:44\n",
      "\u001b[32m[05/18 00:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 1534/1889. 0.7688 s / img. ETA=0:04:44\n",
      "\u001b[32m[05/18 00:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 1541/1889. 0.7688 s / img. ETA=0:04:38\n",
      "\u001b[32m[05/18 00:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 1541/1889. 0.7688 s / img. ETA=0:04:38\n",
      "\u001b[32m[05/18 00:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 1548/1889. 0.7690 s / img. ETA=0:04:33\n",
      "\u001b[32m[05/18 00:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 1548/1889. 0.7690 s / img. ETA=0:04:33\n",
      "\u001b[32m[05/18 00:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 1555/1889. 0.7688 s / img. ETA=0:04:27\n",
      "\u001b[32m[05/18 00:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 1555/1889. 0.7688 s / img. ETA=0:04:27\n",
      "\u001b[32m[05/18 00:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 1561/1889. 0.7690 s / img. ETA=0:04:22\n",
      "\u001b[32m[05/18 00:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 1561/1889. 0.7690 s / img. ETA=0:04:22\n",
      "\u001b[32m[05/18 00:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 1567/1889. 0.7692 s / img. ETA=0:04:18\n",
      "\u001b[32m[05/18 00:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 1567/1889. 0.7692 s / img. ETA=0:04:18\n",
      "\u001b[32m[05/18 00:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 1574/1889. 0.7689 s / img. ETA=0:04:12\n",
      "\u001b[32m[05/18 00:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 1574/1889. 0.7689 s / img. ETA=0:04:12\n",
      "\u001b[32m[05/18 00:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 1580/1889. 0.7691 s / img. ETA=0:04:07\n",
      "\u001b[32m[05/18 00:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 1580/1889. 0.7691 s / img. ETA=0:04:07\n",
      "\u001b[32m[05/18 00:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 1587/1889. 0.7692 s / img. ETA=0:04:02\n",
      "\u001b[32m[05/18 00:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 1587/1889. 0.7692 s / img. ETA=0:04:02\n",
      "\u001b[32m[05/18 00:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 1593/1889. 0.7694 s / img. ETA=0:03:57\n",
      "\u001b[32m[05/18 00:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 1593/1889. 0.7694 s / img. ETA=0:03:57\n",
      "\u001b[32m[05/18 00:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 1600/1889. 0.7691 s / img. ETA=0:03:51\n",
      "\u001b[32m[05/18 00:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 1600/1889. 0.7691 s / img. ETA=0:03:51\n",
      "\u001b[32m[05/18 00:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 1607/1889. 0.7689 s / img. ETA=0:03:46\n",
      "\u001b[32m[05/18 00:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 1607/1889. 0.7689 s / img. ETA=0:03:46\n",
      "\u001b[32m[05/18 00:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 1613/1889. 0.7691 s / img. ETA=0:03:41\n",
      "\u001b[32m[05/18 00:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 1613/1889. 0.7691 s / img. ETA=0:03:41\n",
      "\u001b[32m[05/18 00:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 1619/1889. 0.7693 s / img. ETA=0:03:36\n",
      "\u001b[32m[05/18 00:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 1619/1889. 0.7693 s / img. ETA=0:03:36\n",
      "\u001b[32m[05/18 00:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 1625/1889. 0.7695 s / img. ETA=0:03:31\n",
      "\u001b[32m[05/18 00:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 1625/1889. 0.7695 s / img. ETA=0:03:31\n",
      "\u001b[32m[05/18 00:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 1632/1889. 0.7693 s / img. ETA=0:03:26\n",
      "\u001b[32m[05/18 00:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 1632/1889. 0.7693 s / img. ETA=0:03:26\n",
      "\u001b[32m[05/18 00:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 1639/1889. 0.7692 s / img. ETA=0:03:20\n",
      "\u001b[32m[05/18 00:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 1639/1889. 0.7692 s / img. ETA=0:03:20\n",
      "\u001b[32m[05/18 00:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 1646/1889. 0.7691 s / img. ETA=0:03:14\n",
      "\u001b[32m[05/18 00:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 1646/1889. 0.7691 s / img. ETA=0:03:14\n",
      "\u001b[32m[05/18 00:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 1652/1889. 0.7692 s / img. ETA=0:03:10\n",
      "\u001b[32m[05/18 00:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 1652/1889. 0.7692 s / img. ETA=0:03:10\n",
      "\u001b[32m[05/18 00:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 1659/1889. 0.7690 s / img. ETA=0:03:04\n",
      "\u001b[32m[05/18 00:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 1659/1889. 0.7690 s / img. ETA=0:03:04\n",
      "\u001b[32m[05/18 00:59:36 d2.evaluation.evaluator]: \u001b[0mInference done 1666/1889. 0.7690 s / img. ETA=0:02:58\n",
      "\u001b[32m[05/18 00:59:36 d2.evaluation.evaluator]: \u001b[0mInference done 1666/1889. 0.7690 s / img. ETA=0:02:58\n",
      "\u001b[32m[05/18 00:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 1673/1889. 0.7689 s / img. ETA=0:02:53\n",
      "\u001b[32m[05/18 00:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 1673/1889. 0.7689 s / img. ETA=0:02:53\n",
      "\u001b[32m[05/18 00:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 1679/1889. 0.7690 s / img. ETA=0:02:48\n",
      "\u001b[32m[05/18 00:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 1679/1889. 0.7690 s / img. ETA=0:02:48\n",
      "\u001b[32m[05/18 00:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 1686/1889. 0.7689 s / img. ETA=0:02:42\n",
      "\u001b[32m[05/18 00:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 1686/1889. 0.7689 s / img. ETA=0:02:42\n",
      "\u001b[32m[05/18 00:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 1694/1889. 0.7685 s / img. ETA=0:02:36\n",
      "\u001b[32m[05/18 00:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 1694/1889. 0.7685 s / img. ETA=0:02:36\n",
      "\u001b[32m[05/18 01:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 1700/1889. 0.7689 s / img. ETA=0:02:31\n",
      "\u001b[32m[05/18 01:00:03 d2.evaluation.evaluator]: \u001b[0mInference done 1700/1889. 0.7689 s / img. ETA=0:02:31\n",
      "\u001b[32m[05/18 01:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 1707/1889. 0.7688 s / img. ETA=0:02:25\n",
      "\u001b[32m[05/18 01:00:08 d2.evaluation.evaluator]: \u001b[0mInference done 1707/1889. 0.7688 s / img. ETA=0:02:25\n",
      "\u001b[32m[05/18 01:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 1714/1889. 0.7685 s / img. ETA=0:02:20\n",
      "\u001b[32m[05/18 01:00:13 d2.evaluation.evaluator]: \u001b[0mInference done 1714/1889. 0.7685 s / img. ETA=0:02:20\n",
      "\u001b[32m[05/18 01:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 1721/1889. 0.7688 s / img. ETA=0:02:14\n",
      "\u001b[32m[05/18 01:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 1721/1889. 0.7688 s / img. ETA=0:02:14\n",
      "\u001b[32m[05/18 01:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 1728/1889. 0.7686 s / img. ETA=0:02:09\n",
      "\u001b[32m[05/18 01:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 1728/1889. 0.7686 s / img. ETA=0:02:09\n",
      "\u001b[32m[05/18 01:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 1735/1889. 0.7685 s / img. ETA=0:02:03\n",
      "\u001b[32m[05/18 01:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 1735/1889. 0.7685 s / img. ETA=0:02:03\n",
      "\u001b[32m[05/18 01:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 1742/1889. 0.7685 s / img. ETA=0:01:57\n",
      "\u001b[32m[05/18 01:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 1742/1889. 0.7685 s / img. ETA=0:01:57\n",
      "\u001b[32m[05/18 01:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 1749/1889. 0.7685 s / img. ETA=0:01:52\n",
      "\u001b[32m[05/18 01:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 1749/1889. 0.7685 s / img. ETA=0:01:52\n",
      "\u001b[32m[05/18 01:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 1756/1889. 0.7684 s / img. ETA=0:01:46\n",
      "\u001b[32m[05/18 01:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 1756/1889. 0.7684 s / img. ETA=0:01:46\n",
      "\u001b[32m[05/18 01:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 1763/1889. 0.7684 s / img. ETA=0:01:40\n",
      "\u001b[32m[05/18 01:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 1763/1889. 0.7684 s / img. ETA=0:01:40\n",
      "\u001b[32m[05/18 01:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 1770/1889. 0.7685 s / img. ETA=0:01:35\n",
      "\u001b[32m[05/18 01:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 1770/1889. 0.7685 s / img. ETA=0:01:35\n",
      "\u001b[32m[05/18 01:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 1777/1889. 0.7683 s / img. ETA=0:01:29\n",
      "\u001b[32m[05/18 01:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 1777/1889. 0.7683 s / img. ETA=0:01:29\n",
      "\u001b[32m[05/18 01:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 1784/1889. 0.7683 s / img. ETA=0:01:24\n",
      "\u001b[32m[05/18 01:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 1784/1889. 0.7683 s / img. ETA=0:01:24\n",
      "\u001b[32m[05/18 01:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 1790/1889. 0.7684 s / img. ETA=0:01:19\n",
      "\u001b[32m[05/18 01:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 1790/1889. 0.7684 s / img. ETA=0:01:19\n",
      "\u001b[32m[05/18 01:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 1797/1889. 0.7686 s / img. ETA=0:01:13\n",
      "\u001b[32m[05/18 01:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 1797/1889. 0.7686 s / img. ETA=0:01:13\n",
      "\u001b[32m[05/18 01:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 1804/1889. 0.7684 s / img. ETA=0:01:08\n",
      "\u001b[32m[05/18 01:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 1804/1889. 0.7684 s / img. ETA=0:01:08\n",
      "\u001b[32m[05/18 01:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 1811/1889. 0.7684 s / img. ETA=0:01:02\n",
      "\u001b[32m[05/18 01:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 1811/1889. 0.7684 s / img. ETA=0:01:02\n",
      "\u001b[32m[05/18 01:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 1818/1889. 0.7683 s / img. ETA=0:00:56\n",
      "\u001b[32m[05/18 01:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 1818/1889. 0.7683 s / img. ETA=0:00:56\n",
      "\u001b[32m[05/18 01:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 1824/1889. 0.7684 s / img. ETA=0:00:52\n",
      "\u001b[32m[05/18 01:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 1824/1889. 0.7684 s / img. ETA=0:00:52\n",
      "\u001b[32m[05/18 01:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 1830/1889. 0.7687 s / img. ETA=0:00:47\n",
      "\u001b[32m[05/18 01:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 1830/1889. 0.7687 s / img. ETA=0:00:47\n",
      "\u001b[32m[05/18 01:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 1837/1889. 0.7684 s / img. ETA=0:00:41\n",
      "\u001b[32m[05/18 01:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 1837/1889. 0.7684 s / img. ETA=0:00:41\n",
      "\u001b[32m[05/18 01:01:57 d2.evaluation.evaluator]: \u001b[0mInference done 1844/1889. 0.7683 s / img. ETA=0:00:36\n",
      "\u001b[32m[05/18 01:01:57 d2.evaluation.evaluator]: \u001b[0mInference done 1844/1889. 0.7683 s / img. ETA=0:00:36\n",
      "\u001b[32m[05/18 01:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 1851/1889. 0.7684 s / img. ETA=0:00:30\n",
      "\u001b[32m[05/18 01:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 1851/1889. 0.7684 s / img. ETA=0:00:30\n",
      "\u001b[32m[05/18 01:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 1858/1889. 0.7684 s / img. ETA=0:00:24\n",
      "\u001b[32m[05/18 01:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 1858/1889. 0.7684 s / img. ETA=0:00:24\n",
      "\u001b[32m[05/18 01:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 1865/1889. 0.7683 s / img. ETA=0:00:19\n",
      "\u001b[32m[05/18 01:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 1865/1889. 0.7683 s / img. ETA=0:00:19\n",
      "\u001b[32m[05/18 01:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 1871/1889. 0.7685 s / img. ETA=0:00:14\n",
      "\u001b[32m[05/18 01:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 1871/1889. 0.7685 s / img. ETA=0:00:14\n",
      "\u001b[32m[05/18 01:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 1878/1889. 0.7685 s / img. ETA=0:00:08\n",
      "\u001b[32m[05/18 01:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 1878/1889. 0.7685 s / img. ETA=0:00:08\n",
      "\u001b[32m[05/18 01:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 1884/1889. 0.7686 s / img. ETA=0:00:04\n",
      "\u001b[32m[05/18 01:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 1884/1889. 0.7686 s / img. ETA=0:00:04\n",
      "\u001b[32m[05/18 01:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:25:09.776073 (0.801367 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/18 01:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:25:09.776073 (0.801367 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/18 01:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:24:08 (0.768656 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/18 01:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:24:08 (0.768656 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/18 01:02:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/18 01:02:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/18 01:02:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/inference/coco_instances_results.json\n",
      "\u001b[32m[05/18 01:02:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/inference/coco_instances_results.json\n",
      "\u001b[32m[05/18 01:02:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "\u001b[32m[05/18 01:02:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/18 01:02:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[05/18 01:02:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.88 seconds.\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.88 seconds.\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.61 seconds.\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.61 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category            | AP    | category               | AP    | category       | AP    |\n",
      "|:--------------------|:------|:-----------------------|:------|:---------------|:------|\n",
      "| rov                 | 0.000 | plant                  | 0.000 | animal_fish    | 0.000 |\n",
      "| animal_starfish     | 0.000 | animal_shells          | 0.000 | animal_crab    | 0.000 |\n",
      "| animal_eel          | 0.000 | animal_etc             | 0.000 | trash_clothing | 0.000 |\n",
      "| trash_pipe          | 0.000 | trash_bottle           | 0.000 | trash_bag      | 0.000 |\n",
      "| trash_snack_wrapper | 0.000 | trash_can              | 0.000 | trash_cup      | 0.000 |\n",
      "| trash_container     | 0.000 | trash_unknown_instance | 0.000 | trash_branch   | 0.000 |\n",
      "| trash_wreckage      | 0.000 | trash_tarp             | 0.000 | trash_rope     | 0.000 |\n",
      "| trash_net           | 0.000 |                        |       |                |       |\n",
      "\u001b[32m[05/18 01:02:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category            | AP    | category               | AP    | category       | AP    |\n",
      "|:--------------------|:------|:-----------------------|:------|:---------------|:------|\n",
      "| rov                 | 0.000 | plant                  | 0.000 | animal_fish    | 0.000 |\n",
      "| animal_starfish     | 0.000 | animal_shells          | 0.000 | animal_crab    | 0.000 |\n",
      "| animal_eel          | 0.000 | animal_etc             | 0.000 | trash_clothing | 0.000 |\n",
      "| trash_pipe          | 0.000 | trash_bottle           | 0.000 | trash_bag      | 0.000 |\n",
      "| trash_snack_wrapper | 0.000 | trash_can              | 0.000 | trash_cup      | 0.000 |\n",
      "| trash_container     | 0.000 | trash_unknown_instance | 0.000 | trash_branch   | 0.000 |\n",
      "| trash_wreckage      | 0.000 | trash_tarp             | 0.000 | trash_rope     | 0.000 |\n",
      "| trash_net           | 0.000 |                        |       |                |       |\n",
      "Loading and preparing results...\n",
      "DONE (t=4.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[05/18 01:02:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[05/18 01:02:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[05/18 01:02:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 4.64 seconds.\n",
      "\u001b[32m[05/18 01:02:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 4.64 seconds.\n",
      "\u001b[32m[05/18 01:02:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/18 01:02:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.62 seconds.\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.62 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.312 | 29.107 | 11.687 | 7.487 | 18.962 | 31.681 |\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.312 | 29.107 | 11.687 | 7.487 | 18.962 | 31.681 |\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category            | AP     | category               | AP     | category       | AP     |\n",
      "|:--------------------|:-------|:-----------------------|:-------|:---------------|:-------|\n",
      "| rov                 | 34.475 | plant                  | 3.995  | animal_fish    | 2.571  |\n",
      "| animal_starfish     | 0.222  | animal_shells          | 4.863  | animal_crab    | 6.353  |\n",
      "| animal_eel          | 5.832  | animal_etc             | 8.490  | trash_clothing | 7.701  |\n",
      "| trash_pipe          | 29.338 | trash_bottle           | 27.332 | trash_bag      | 14.166 |\n",
      "| trash_snack_wrapper | 4.877  | trash_can              | 29.566 | trash_cup      | 27.342 |\n",
      "| trash_container     | 34.892 | trash_unknown_instance | 4.314  | trash_branch   | 25.803 |\n",
      "| trash_wreckage      | 20.012 | trash_tarp             | 17.497 | trash_rope     | 4.562  |\n",
      "| trash_net           | 0.669  |                        |        |                |        |\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category            | AP     | category               | AP     | category       | AP     |\n",
      "|:--------------------|:-------|:-----------------------|:-------|:---------------|:-------|\n",
      "| rov                 | 34.475 | plant                  | 3.995  | animal_fish    | 2.571  |\n",
      "| animal_starfish     | 0.222  | animal_shells          | 4.863  | animal_crab    | 6.353  |\n",
      "| animal_eel          | 5.832  | animal_etc             | 8.490  | trash_clothing | 7.701  |\n",
      "| trash_pipe          | 29.338 | trash_bottle           | 27.332 | trash_bag      | 14.166 |\n",
      "| trash_snack_wrapper | 4.877  | trash_can              | 29.566 | trash_cup      | 27.342 |\n",
      "| trash_container     | 34.892 | trash_unknown_instance | 4.314  | trash_branch   | 25.803 |\n",
      "| trash_wreckage      | 20.012 | trash_tarp             | 17.497 | trash_rope     | 4.562  |\n",
      "| trash_net           | 0.669  |                        |        |                |        |\n",
      "\u001b[32m[05/18 01:02:56 d2.engine.defaults]: \u001b[0mEvaluation results for trashcan_instance_val in csv format:\n",
      "\u001b[32m[05/18 01:02:56 d2.engine.defaults]: \u001b[0mEvaluation results for trashcan_instance_val in csv format:\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: 14.3124,29.1072,11.6865,7.4866,18.9622,31.6807\n",
      "\u001b[32m[05/18 01:02:56 d2.evaluation.testing]: \u001b[0mcopypaste: 14.3124,29.1072,11.6865,7.4866,18.9622,31.6807\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "args = argparse.Namespace(config_file='configs/SOLOv2/R50_1x.yaml',\n",
    "                          dist_url='tcp://127.0.0.1:49153',\n",
    "                          eval_only=True,\n",
    "                          machine_rank=0,\n",
    "                          num_gpus=1,\n",
    "                          num_machines=1,\n",
    "                          opts=['OUTPUT_DIR', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/final_test2/',\n",
    "                                'MODEL.WEIGHTS', '/home/outletters/trashcan/training_dir/SOLOv2_R50_1x/model_0003599.pth'],\n",
    "                          resume=False)\n",
    "print(\"Command Line Args:\", args)\n",
    "launch(\n",
    "        main,\n",
    "        args.num_gpus,\n",
    "        num_machines=args.num_machines,\n",
    "        machine_rank=args.machine_rank,\n",
    "        dist_url=args.dist_url,\n",
    "        args=(args,),\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
